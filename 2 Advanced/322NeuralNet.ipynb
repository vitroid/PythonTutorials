{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "322NeuralNet.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vitroid/PythonTutorials/blob/master/2%20Advanced/322NeuralNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYyc_sdQzB_e"
      },
      "source": [
        "# ニューラルネットワーク\n",
        "人工ニューラルネットワーク(ANN, 人工神経回路網)は、近年になって急激に脚光を浴びはじめた。\n",
        "\n",
        "1. **これまでの手法の限界**\n",
        "   教える(=認識する)内容が複雑になるにつれ、人によるパラメータチューニングに限界が見えてきた。\n",
        "\n",
        "2. **NNにおけるブレークスルー**\n",
        "   NN自体は1940年代から研究が始まっていたが、性能が伸び悩み、実用には向かないと考えられていた。今世紀に入りそれを打破する新しいアイディアにより、人の手助けなしに、自律的に極めて高度な学習ができるようになった。\n",
        "   \n",
        "3. **データ量の増大**\n",
        "   デジタル写真や音声データが一般化し、膨大な教師データを準備できるようになった。\n",
        "   \n",
        "4. **計算機性能の向上**\n",
        "   膨大な量のトレーニングができるようになった。\n",
        "   \n",
        "## ANNとは何か\n",
        "神経細胞(ニューロン)の信号伝達をモデル化し、それを大量に組みあわせてネットワーク化して脳の信号処理を模倣する試み。脳機能を忠実に再現しているわけではない。\n",
        "\n",
        "## 何ができるのか\n",
        "画像や音声などの、大きなデータを入力し、分類、エンコーディング、認識、タグ付け、ノイズ除去などのさまざまなタスクを行う。最新のディープニューラルネットワークを用いると、画像認識、文字認識等で人間を越える能力を発揮する。\n",
        "\n",
        "## ディープラーニングとは何か\n",
        "ディープニューラルネットワークを用いた機械学習。\n",
        "\n",
        "## ディープニューラルネットワークとは何か\n",
        "ネットワークの階層性が深いニューラルネットワークのこと。2016年現在、「非常に深い」ニューラルネットワークとは10層程度を指していたが、2018年にはすでに何十層もあるのがあたりまえになりつつある。基本的な構造はどのニューラルネットワークも同じだが、ディープニューラルネットワークを設計する場合には、各階層に役割を与える場合が多い。\n",
        "\n",
        "## もてはやされる理由\n",
        "\n",
        "1. 人力では達成不可能な複雑なタスクを実現できるようになった。\n",
        "\n",
        "2. 学習過程での計算量は莫大だが、一旦学習したあとは、かけ算と足し算の組みあわせによる、わずかな計算しか必要としない = スマホ程度の計算能力で十分利用できる。\n",
        "\n",
        "## 我々科学者の立ち位置\n",
        "1. DNNの開発に参入するのは難しい。計算機シミュレーションのために、半導体設計から始めるようなもの。よほどの勝算がなければやめておいたほうがいい。\n",
        "2. DNNで何ができ、何ができないかを理解した上で、DNNに適合するような問題設定を考える。既存のフレームワーク(TensorFlowなど)を使って自力で解くか、外部専門家に適切な要望を出して解決してもらう。\n",
        "\n",
        "## フレームワーク\n",
        "フレームワークとは、ニューラルネットワークを計算機に実装する一連の作業に必要なツール一式のこと。フレームワークが違うと、重みやバイアスといった変数をどんな形式で指定するか、バックプロパゲーションをどのように実施するか、などといった作業手順が違ってくる。\n",
        "\n",
        "適切なフレームワークを選べば、計算機の性能を最大限にひきだせる。複数のGPUを使って計算を加速したり、外部のCloudに任せてしまうことすら可能。(例えばAmazonのクラウドAWSはMXNetやTensorFlowに対応しているらしい)\n",
        "\n",
        "(July 2018)\n",
        "\n",
        "|FW name | 公開年   | 開発主体 | 言語  |github|\n",
        "|:---:|:---:|:------|:-----|:---|\n",
        "|Theano |(2010) |MontrealU |Python|[Theano/Theano](https://github.com/Theano/Theano)\n",
        "|Caffe   |2013     |UCB      |C++, Python|[BVLC/caffe](https://github.com/BVLC/caffe)\n",
        "|Chainer |2015     |PFN      |Python |[chainer/chainer](https://github.com/chainer/chainer)\n",
        "|CNTK    |2015      |Microsoft |Python|[Microsoft/CNTK](https://github.com/Microsoft/CNTK)\n",
        "|TensorFlow | 2015 | Google | C++, Python |[tensorflow/tensorflow](https://github.com/tensorflow/tensorflow)\n",
        "|neon    |2015   |Intel     |Python|[NervanaSystems/neon](https://github.com/NervanaSystems/neon)\n",
        "|PyTorch |2016   |NYU, Facebook|Python|[pytorch/pytorch](https://github.com/pytorch/pytorch)\n",
        "|NNabla  |2017   |Sony      |C++, Python   |[sony/nnabla](https://github.com/sony/nnabla)\n",
        "|Caffe2  |2017     |Facebook |C++, Python|[caffe2/caffe2](https://github.com/caffe2/caffe2)\n",
        "|MXNet   |2017     |WU, CMU  |Python, R, Julia, Go|[apache/incubator-mxnet](https://github.com/apache/incubator-mxnet)\n",
        "\n",
        "* Pythonが書ければ、どれも使える。\n",
        "* どのプロジェクトも、[github](https://github.com)でソースプログラムを公開している。\n",
        "* https://qiita.com/bonotake/items/cbd44abbcbe333f264d8 などを参考に整理\n",
        "* (2020)もうすでにだいぶ古い情報になっている。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGuoio9zIr4L"
      },
      "source": [
        "(2020追記) いろいろごたくを書いたが、もっとビジュアルな説明を見て下さい。 https://www.codexa.net/what-is-deep-learning/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWHo1p_nzB_g"
      },
      "source": [
        "## TensorFlowによる実装例\n",
        "\n",
        "TensorFlowはGoogleが提供しているNNフレームワーク。次のサイトで教師あり学習の利用例をブラウザ上で試すことができる: https://playground.tensorflow.org\n",
        "\n",
        "ここでは、https://www.tensorflow.org/versions/r1.0/get_started/mnist/beginners をなぞってみる。(2020 すでにこれは動かなくなっている。変化が速い)\n",
        "\n",
        "MNISTは教師あり学習のための手書き数字のデータセットである。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrCFtbR75gub"
      },
      "source": [
        "以下のプログラムは、 https://www.tensorflow.org/overview/?hl=ja からそのままもってきた。最近のtensorflowはkerasと組みあわせて使うのが標準的なのか。たしかに以前のtensorflowに比べて格段に書きやすい。\n",
        "\n",
        "内容の説明は https://www.tensorflow.org/tutorials/quickstart/beginner?hl=ja にある。ここでは簡単にコメントを入れる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXhdI98k4bu7"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# MNISTは数字画像認識の教師データ\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# 訓練データと検証データを読みこむ。\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 255階調の画像データを0〜1の実数階調に変換。\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x_train, y_train # 画像データ と 読み方データ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uWTHyPV58Dp"
      },
      "source": [
        "# Neural Networkの設計図(どんな層をどんな順に通すか)\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 最適化の方法の指示(シナプス結合の最適化)\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 最適化の実行\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "# 結果の評価(検証データでの評価)\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQIAKUuCFjQ-"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# どの文字かを確率で表している。\n",
        "y_prob = model.predict(x_test)\n",
        "# 確率が最大の文字を選ぶ。\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "\n",
        "# 画像データの表示\n",
        "fig, ax = plt.subplots(12, 12, figsize=(6, 6))\n",
        "fig.subplots_adjust(left=0,right=1, bottom=0,top=1,hspace=0.05,wspace=0.05)\n",
        "for i, axi in enumerate(ax.flat):\n",
        "    axi.set(xticks=[], yticks=[])\n",
        "\n",
        "    if y_pred[i] != y_test[i]:\n",
        "        axi.text(0,7,str(y_pred[i]), color='red')\n",
        "        axi.imshow((x_test[i]).reshape(28,28), cmap='Reds')\n",
        "    else:\n",
        "        axi.imshow(x_test[i].reshape(28,28), cmap='binary')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w69eLBuazCAN"
      },
      "source": [
        "赤字がNNの予測なのだが、正直言ってこれを読み違えてもしかたないだろうと思える。\n",
        "\n",
        "テストデータセットでの正答率は98%。たいして工夫してないニューラルネットワークでもこれだけの性能がでるようになった。しかも後で比較する決定木やランダムフォレストに比べても格段に速い。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDZh5ZnHzCAz"
      },
      "source": [
        "### 従来法との比較\n",
        "\n",
        "同じことを決定木で試してみよう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyPiOw8dzCAz"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxbuu47szCA6"
      },
      "source": [
        "28x28=784次元は可視化できないので、決定木の生成はライブラリを信じるしかない。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ9litZYzCA6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 分類器を準備する\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# 画像を1次元のデータ列に読みかえる。\n",
        "x_train = x_train.reshape(60000,28*28)\n",
        "x_test  = x_test.reshape(10000,28*28)\n",
        "\n",
        "#まず教師データで学習させる\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "#その結果を使ってtestデータを分類してエラーを測定する。\n",
        "ypred = model.predict(x_test)\n",
        "\n",
        "ypred, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKBmWl94zCA8"
      },
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.classification_report(ypred, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFbOH-64HQXH"
      },
      "source": [
        "# 画像データの表示\n",
        "fig, ax = plt.subplots(12, 12, figsize=(6, 6))\n",
        "fig.subplots_adjust(left=0,right=1, bottom=0,top=1,hspace=0.05,wspace=0.05)\n",
        "for i, axi in enumerate(ax.flat):\n",
        "    axi.set(xticks=[], yticks=[])\n",
        "\n",
        "    if ypred[i] != y_test[i]:\n",
        "        axi.text(0,7,str(ypred[i]), color='red')\n",
        "        axi.imshow((x_test[i]).reshape(28,28), cmap='Reds')\n",
        "    else:\n",
        "        axi.imshow(x_test[i].reshape(28,28), cmap='binary')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2finyJGhzCA-"
      },
      "source": [
        "正解率88%。\n",
        "\n",
        "次はRandomForestを使ってみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjRkDe8lzCA-"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble        import RandomForestClassifier\n",
        "\n",
        "# 分類器を準備する\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# 画像を1次元のデータ列に読みかえる。\n",
        "x_train = x_train.reshape(60000,28*28)\n",
        "x_test  = x_test.reshape(10000,28*28)\n",
        "\n",
        "#まず教師データで学習させる\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "#その結果を使ってtestデータを分類してエラーを測定する。\n",
        "ypred = model.predict(x_test)\n",
        "\n",
        "ypred, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gln_Gvk2zCBA"
      },
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.classification_report(ypred, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD_Z8c-NHe7d"
      },
      "source": [
        "# 画像データの表示\n",
        "fig, ax = plt.subplots(12, 12, figsize=(6, 6))\n",
        "fig.subplots_adjust(left=0,right=1, bottom=0,top=1,hspace=0.05,wspace=0.05)\n",
        "for i, axi in enumerate(ax.flat):\n",
        "    axi.set(xticks=[], yticks=[])\n",
        "\n",
        "    if ypred[i] != y_test[i]:\n",
        "        axi.text(0,7,str(ypred[i]), color='red')\n",
        "        axi.imshow((x_test[i]).reshape(28,28), cmap='Reds')\n",
        "    else:\n",
        "        axi.imshow(x_test[i].reshape(28,28), cmap='binary')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SX6K2PClzCBC"
      },
      "source": [
        "正答率97%。これでもかなり性能が良いとは思うが、このへんがDeep Learning以前の限界に近い。ちなみに人間の性能は95〜98%。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMd6-GJ0zCBC"
      },
      "source": [
        "## ニューラルネットワークのレイヤーを増やして精度を高める\n",
        "\n",
        "2019年にkerasで書いたコードは、書法がかなり変わったので使えそうにない。(その代わりかなりシンプルに書けるようになっている。)全部書きかえた。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMT1rDG8-Mm3"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# MNISTは数字画像認識の教師データ\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# 訓練データと検証データを読みこむ。\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 255階調の画像データを0〜1の実数階調に変換。\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# 画像処理用に特化したNNなので、2次元のまま操作する\n",
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)\n",
        "\n",
        "# Neural Networkの設計図(どんな層をどんな順に通すか)\n",
        "\n",
        "# Neural Networkのトポロジー定義\n",
        "# Kerasのサンプルから切り貼り。もともとは数字用ではないかもしれない。\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  tf.keras.layers.Dropout(0.25),\n",
        "  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  tf.keras.layers.Dropout(0.25),\n",
        "  tf.keras.layers.Flatten(), # input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 最適化の方法の指示(シナプス結合の最適化)\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 最適化の実行\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "# 結果の評価(検証データでの評価)\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww4sTErqzCBF"
      },
      "source": [
        "* Conv2Dは畳み込み層(隣のピクセルだけから次の層の値を算出する)\n",
        "* MaxPoolingはプーリング層(最大値だけを選んで粗視化)\n",
        "* Denseは全結合層\n",
        "* dropoutは結合を間引いた全結合層(ランダムに結合を間引くことで「打たれ強い」(過学習になりにくい)ネットワークを作る)\n",
        "* Flattenは平滑化層。\n",
        "\n",
        "これを見ると、このネットワークは12層の中間層を持つ深いNNであることがよみとれる。どんな層をどんな順番で組み立てるかが性能を左右するが、それ自体も機械学習で最適化させるべき対象だろう。個々の層の役割についてはNeural Networkの教科書かネットの情報を参照してほしい。\n",
        "\n",
        "データの量もかなり多い(60000個×784ピクセル)が、最適化すべきパラメータの数(33万)も多い。複雑さという点では決定木をはるかにしのぐと言える。\n",
        "\n",
        "正答率は99%を超えた。人間よりも性能がよさそうだ。\n",
        "\n",
        "なお、2019年に自分のPCで実行した時は、469 step x 50 epoch (epochはパラメータ最適化の回数)で4時間かかったと書いてあった。今年はGoogleの計算機で、1875 steps x 5 epochで12分程度なので、相当速くなっている。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPQjYt3aH69V"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "y_prob = model.predict(x_test)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "\n",
        "# 画像データの表示\n",
        "fig, ax = plt.subplots(12, 12, figsize=(6, 6))\n",
        "fig.subplots_adjust(left=0,right=1, bottom=0,top=1,hspace=0.05,wspace=0.05)\n",
        "for i, axi in enumerate(ax.flat):\n",
        "    axi.set(xticks=[], yticks=[])\n",
        "\n",
        "    if y_pred[i] != y_test[i]:\n",
        "        axi.text(0,7,str(y_pred[i]), color='red')\n",
        "        axi.imshow((x_test[i]).reshape(28,28), cmap='Reds')\n",
        "    else:\n",
        "        axi.imshow(x_test[i].reshape(28,28), cmap='binary')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2AvOL8_zCBK"
      },
      "source": [
        "てきとうにサンプルから切り貼りした(最適化してない)DNNでも99.1%が達成された。人間をはるかに凌ぐ性能!\n",
        "\n",
        "もはや特別な知識をもたなくても、画像を認識し、人間以上の精度で識別することが可能になっている。\n",
        "\n",
        "あなたの研究で、どんな側面にこれを利用できるだろうか。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 応用\n",
        "\n",
        "パソコンのカメラで数字を見せて、それを読みとれるか。\n",
        "\n",
        "まず、カメラから画像をとりこむ。今回は、Google Colab(クラウド)上でプログラムを走らせているので、動画撮影はできない。"
      ],
      "metadata": {
        "id": "qaJ3A2R9dIMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "metadata": {
        "id": "aEWsDW-NeV3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "metadata": {
        "id": "dH_mPmCbeV3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# 学習に使ったのと同じように、白黒の画像にする。\n",
        "img = cv2.imread(filename)\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n"
      ],
      "metadata": {
        "id": "P7qCEygfeXpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gray"
      ],
      "metadata": {
        "id": "kRIbpXELf-xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Colab users\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# 二値化します。\n",
        "ret, thresh_value = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "cv2_imshow(thresh_value)\n"
      ],
      "metadata": {
        "id": "23STJ21zhEdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 白部分を膨らませる\n",
        "\n",
        "kernel = np.ones((10,10),np.uint8)\n",
        "dilated_value = cv2.dilate(thresh_value,kernel,iterations = 1)\n",
        "\n",
        "cv2_imshow(dilated_value)"
      ],
      "metadata": {
        "id": "h4454fwfjnsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 等高線(輪郭線)をみつける。\n",
        "contours, hierarchy = cv2.findContours(dilated_value, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n"
      ],
      "metadata": {
        "id": "iWFGuf96ieKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rects = img.copy()\n",
        "\n",
        "# 輪郭線を含む長方形をすべて描く。\n",
        "for cnt in contours:\n",
        "    x, y, w, h = cv2.boundingRect(cnt)\n",
        "    # bounding the images\n",
        "    rects = cv2.rectangle(rects, (x, y), (x + w, y + h), (0, 0, 255), 1)\n",
        "\n",
        "cv2_imshow(rects)"
      ],
      "metadata": {
        "id": "belwCgUOkmin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# それぞれの長方形を、数字だと思って、NNに認識させる。\n",
        "detects = img.copy()\n",
        "\n",
        "for cnt in contours:\n",
        "    x, y, w, h = cv2.boundingRect(cnt)\n",
        "    # 輪郭線長方形の部分だけを切りだしてコピーを作る。\n",
        "    letter = thresh_value[y:y+h, x:x+w].copy()\n",
        "    # 28x28ピクセルにする。\n",
        "    letter = cv2.resize(letter, (28,28))\n",
        "    # Arrayの形を、x_testと同じ4次元にする。-1を指定した次元はてきとうに設定してくれる。\n",
        "    letter = letter.reshape(1,28,28,-1)\n",
        "    # 階調を0〜1にして予測する。\n",
        "    y_prob = model.predict(letter / 255)\n",
        "    # 一番確率が大きかった文字を選ぶ。\n",
        "    y_pred = np.argmax(y_prob, axis=1)\n",
        "    # 長方形枠を描く。\n",
        "    detects = cv2.rectangle(detects, (x, y), (x + w, y + h), (0, 0, 255), 1)\n",
        "    # 認識した数字を描く。\n",
        "    cv2.putText(img=detects, text=f'{y_pred[0]}', org=(x, y), fontFace=cv2.FONT_HERSHEY_TRIPLEX, fontScale=1, color=(0, 0, 255),thickness=1)\n",
        "\n",
        "cv2_imshow(detects)"
      ],
      "metadata": {
        "id": "bpIGW-Ifk2U-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YYS7ykNDnJdj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}