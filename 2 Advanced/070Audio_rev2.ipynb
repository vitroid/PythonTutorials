{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 信号処理の練習\n",
    "\n",
    "## はじめに\n",
    "### `soundfile`のインストール\n",
    "\n",
    "## Guitar (string mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpyを使う例として、音声の合成と解析を行う。\n",
    "\n",
    "基底音: 正弦波(440 Hz, ド)\n",
    "\n",
    "サンプリング周波数は20000 Hzとする。\n",
    "\n",
    "* `time`は文字通り時間。20000個のarrayの中に時刻が書かれている。\n",
    "* `phase`は位相(角度)。$2\\pi$増えるとサイン波が0に戻る。440 Hzの場合は、1秒(20000サンプル)のあいだに$440\\cdot 2\\pi$だけ増加する。\n",
    "* `wave`は波形。ここではコサイン波を作る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from math import pi\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "time = np.linspace(0, 1.0, 20000)\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = time* (440*pi*2)\n",
    "wave = np.cos(phase)\n",
    "\n",
    "#plot the wave\n",
    "plt.xlim(0,0.02)\n",
    "plt.ylim(-1,10)\n",
    "plt.plot(time, phase)\n",
    "plt.plot(time, wave)\n",
    "\n",
    "Audio(wave, rate=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "減衰させる。減衰の時定数は0.5 (0.5秒で$1/e$まで減衰する)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay = np.exp(-time/0.5)\n",
    "\n",
    "Audio(wave*decay, rate=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2倍音。(振動数が2倍の音、1オクターブ上の音)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave = np.cos(2*phase)\n",
    "\n",
    "#plot the wave\n",
    "plt.xlim(0,0.02)\n",
    "plt.plot(time, wave*decay)\n",
    "\n",
    "Audio(wave*decay, rate=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3倍音。(振動数が3倍の音、1オクターブ上のソ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave = np.cos(3*phase)\n",
    "\n",
    "#plot the wave\n",
    "plt.xlim(0,0.02)\n",
    "plt.plot(time, wave*decay)\n",
    "\n",
    "Audio(wave*decay, rate=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4倍音。(振動数が4倍の音、2オクターブ上の同音)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave = np.cos(4*phase)\n",
    "\n",
    "#plot the wave\n",
    "plt.xlim(0,0.02)\n",
    "plt.plot(time, wave*decay)\n",
    "\n",
    "Audio(wave*decay, rate=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基底音+倍音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave = np.cos(phase)\n",
    "wave += 0.5**0.5*np.cos(2*phase)\n",
    "\n",
    "#plot the wave\n",
    "plt.xlim(0,0.02)\n",
    "plt.plot(time, wave*decay)\n",
    "\n",
    "Audio(wave*decay, rate=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基底音+倍音+3倍音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave = np.cos(phase)\n",
    "wave += (1/2)**0.5*np.cos(2*phase)\n",
    "wave += (1/3)**0.5*np.cos(3*phase)\n",
    "\n",
    "#plot the wave\n",
    "plt.xlim(0,0.02)\n",
    "plt.plot(time, wave*decay)\n",
    "\n",
    "Audio(wave*decay, rate=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基底音+倍音+3倍音+4倍音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave = np.cos(phase)\n",
    "wave += (1/2)**0.5*np.cos(2*phase)\n",
    "wave += (1/3)**0.5*np.cos(3*phase)\n",
    "wave += (1/4)**0.5*np.cos(4*phase)\n",
    "\n",
    "#plot the wave\n",
    "plt.xlim(0,0.02)\n",
    "plt.plot(time, wave*decay)\n",
    "\n",
    "Audio(wave*decay, rate=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave = np.cos(phase)\n",
    "wave += (1/2)**0.5*np.cos(2*phase)\n",
    "wave += (1/3)**0.5*np.cos(3*phase)\n",
    "wave += (1/4)**0.5*np.cos(4*phase)\n",
    "wave += (1/3)**0.5*np.cos(5*phase)\n",
    "\n",
    "#plot the wave\n",
    "plt.xlim(0,0.02)\n",
    "plt.plot(time, wave*decay)\n",
    "\n",
    "Audio(wave*decay, rate=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上の波をフーリエ変換してパワースペクトル(周波数分布)を求める。\n",
    "\n",
    "ここで利用するフーリエ変換の定義式は次のリンクを参照: https://docs.scipy.org/doc/numpy/reference/routines.fft.html#module-numpy.fft\n",
    "\n",
    "フーリエ変換は、信号波$f(t)$に、いろんな正弦波(サイン波、コサイン波)を重ねて積分し、成分に分解する。\n",
    "$$F(\\omega)=\\int_{-\\infty}^\\infty f(t)\\cos(2\\pi\\omega t)\\mathrm{d}t+i\\int_{-\\infty}^\\infty f(t)\\sin(2\\pi\\omega t)\\mathrm{d}t=\\int_{-\\infty}^\\infty f(t)\\exp(2\\pi i\\omega t)\\mathrm{d}t$$\n",
    "\n",
    "$N$個の離散的なデータ列$f(k)$ $(k=[1..N])$の場合には、離散的フーリエ変換を用いる。\n",
    "$$F(k)=\\sum_{j=1}^N f(k)\\cos\\left({2\\pi j k\\over N}\\right)+i\\sum_{j=1}^N f(k)\\sin\\left({2\\pi j k\\over N}\\right)=\\sum_{j=1}^N f(k)\\exp\\left({2\\pi j k\\over N}\\right)$$\n",
    "(本によって微妙に定義が違う場合があるので注意)\n",
    "\n",
    "1秒分(20000点)の実数データ列をフーリエ変換すると、結果も20000点得られる。フーリエ変換後に得られるarrayの`[1]`番目の値は、1 Hzの成分(実部がcos、虚部がsin)、`[2]`番目が、2 Hz、という具合に対応する。なお、もし元データが10秒分あるなら、`[1]`番目の成分は1/10=0.1 Hzに対応する。`[0]`番目は直流成分(振動しない成分、オフセット)を表す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = np.fft.fft(wave)\n",
    "\n",
    "#plot the spectrum\n",
    "plt.xlim(0,3000)\n",
    "plt.plot(np.abs(spec)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`abs()`関数は複素数の絶対値も計算できる。この場合、余弦波の振幅(実数)と正弦波の振幅(虚数)の二乗和を計算しているので、波の振幅の二乗=パワーをプロットしていることになる。分光器で測定するスペクトルも出力されているのは光の振幅の二乗=強度(パワー)である。\n",
    "\n",
    "合成した波の成分に戻すことができた。ここでは音声データを分解したが、波データであれば光であれ音声であれ、こうしてスペクトルにに変換できる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timpani (circular membrane modes)\n",
    "膜の振動は、共鳴的ではない。固有振動が無理数比の成分を含み、濁った音になる。\n",
    "\n",
    "基底音の周波数を120 Hzとする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.linspace(0, 5, 20000*5)\n",
    "phase = time * 120 * 2*pi\n",
    "decay = np.exp(-time / 0.5)\n",
    "\n",
    "wave = np.sin(phase)\n",
    "# 倍音の強度はてきとう。\n",
    "wave += (1/2)**0.5*np.sin(1.59*phase)\n",
    "wave += (1/3)**0.5*np.sin(2.14*phase)\n",
    "wave += (1/4)**0.5*np.sin(2.30*phase)\n",
    "wave += (1/3)**0.5*np.sin(2.65*phase)\n",
    "wave += (1/6)**0.5*np.sin(2.92*phase)\n",
    "wave += (1/7)**0.5*np.sin(3.16*phase)\n",
    "wave += (1/8)**0.5*np.sin(3.50*phase)\n",
    "wave += (1/9)**0.5*np.sin(3.60*phase)\n",
    "\n",
    "#plot the wave\n",
    "plt.xlim(0,0.02)\n",
    "plt.plot(time, wave*decay)\n",
    "\n",
    "\n",
    "Audio(wave*decay, rate=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waveは5秒のデータ\n",
    "spec = np.fft.fft(wave)\n",
    "spec = spec[:3000]\n",
    "\n",
    "#plot the spectrum\n",
    "# データが5秒分ある場合、波数の最小目盛は1/5波数となる。\n",
    "wavenumbers = np.arange(0, 600, 1/5)\n",
    "plt.plot(wavenumbers, np.abs(spec)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 宿題1\n",
    "\n",
    "sampleaudio.wav (長さ1秒、サンプリング周波数20000 Hz)に含まれる音の基底振動数を調べよ。\n",
    "\n",
    "wavファイルを読みこむには、`soundfile`モジュールを使うと便利。 (https://stackoverflow.com/questions/34416283/how-to-properly-decode-wav-with-python)\n",
    "\n",
    "* Anacondaでsoundfileを使えるようにし、kernelを再起動する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "wave, samplerate = sf.read(\"sampleaudio.wav\")\n",
    "\n",
    "Audio(wave, rate=samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## もう少し長い音楽データを扱う\n",
    "\n",
    "信号を加工する練習として、音楽データをいじってみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "\n",
    "wave, samplerate = sf.read(\"MyWay.wav\")\n",
    "# samplerate = sound.frame_rate\n",
    "# data = np.array(sound.get_array_of_samples())\n",
    "print(np.min(wave))\n",
    "left= wave[:,0]\n",
    "right = wave[:,1]\n",
    "\n",
    "samplerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1秒間を44100分割して波形を記録していることがわかった。\n",
    "\n",
    "左右を平均してモノラル再生。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mono = (left+right)/2\n",
    "Audio(mono, rate=samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "左右トラックの相関を見てみよう。(データが多すぎるので、100個おき)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(left[::100],right[::100],'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然だが、左右トラックはかなり相関が強い。では、左右を引き算すると?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = left-right\n",
    "Audio(diff, rate=samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "音声の最初の部分をグラフ表示。\n",
    "\n",
    "毎秒44100個もデータがあるので、100個に1個まで間引く。最初の3秒分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(mono[::100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "時刻を1/10秒(4410コマ)ずらして、少し弱くして音を重ねると、反響音(リバーブ)に聞こえる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverb = mono.copy()\n",
    "reverb[4410:] += mono[:-4410]*0.5\n",
    "Audio(reverb, rate=samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ちょっと安っぽいので、ずらす長さを小さくし、何重にも重ねてみる。(反響音は指数関数的に減衰すると仮定)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverb = mono.copy() / 2 # 音をたくさん重ねるので、音量をあらかじめ小さくしておく。\n",
    "\n",
    "delay=int(44100*0.05)\n",
    "reverb[delay:] += mono[:-delay]/2\n",
    "reverb[delay*2:] += mono[:-delay*2]/4\n",
    "reverb[delay*3:] += mono[:-delay*3]/8\n",
    "reverb[delay*4:] += mono[:-delay*4]/16\n",
    "reverb[delay*5:] += mono[:-delay*5]/32\n",
    "reverb[delay*6:] += mono[:-delay*6]/64\n",
    "reverb[delay*7:] += mono[:-delay*7]/128\n",
    "Audio(reverb, rate=samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上でやっているのはこんな感じの重ねあわせ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time=np.linspace(0,3,44100*3)\n",
    "plt.plot(time, mono[:44100*3])\n",
    "plt.plot(time+0.05, mono[:44100*3]/2)\n",
    "plt.plot(time+0.10, mono[:44100*3]/4)\n",
    "plt.plot(time+0.15, mono[:44100*3]/8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これをたくさん行うことは、音声$f(t)$と、残響特性である指数関数$g=\\exp(-at)$ (ただし$t>0$)の「畳み込み」を行うことにほかならない。\n",
    "\n",
    "関数fとgの畳み込み(畳み込み積分)は次のように定義される。\n",
    "\n",
    "$$(f*g)(t)=\\int f(u)g(t-u)\\mathrm{d}u$$\n",
    "\n",
    "音声データ$f$がデルタ関数なら、畳み込み積分は$g$そのものになる。(例えば、風呂の中で手をたたけば、風呂の残響特性がわかる)そのため、$g$のことを音響学では「インパルス応答」と呼ぶ。\n",
    "\n",
    "numpyの畳み込み積分をそのまま使い、音声に残響を付けてみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "time = np.linspace(0, 0.1, 4410)\n",
    "response = np.exp(-time*30) # 0.1秒で1/e^3 = 1/20に減衰する指数関数\n",
    "plt.plot(time,response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.convolve(mono, response, mode='same')\n",
    "Audio(output, rate=samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "こもるばかりであまりうまくいかない。試しにインパルス応答だけ聞いてみるが、音らしく聞こえない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(response, rate=samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "調べてみると、インパルス応答を集めているサイト(www.openairlib.net/auralizationdb)があるらしい。そこで、教会のインパルス応答をもらってくる。\n",
    "\n",
    "The Lady Chapel, St Albans Cathedral, England  https://en.wikipedia.org/wiki/St_Albans_Cathedral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "response, samplerate = sf.read(\"stalbans_a_mono.wav\")\n",
    "\n",
    "Audio(response, rate=samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本物のインパルス応答は、確かに教会で手を叩いた時の残響に聞こえるから面白い(あたりまえだけど)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(response)\n",
    "plt.show()\n",
    "\n",
    "#縦拡大\n",
    "plt.ylim(-0.01,0.01)\n",
    "plt.plot(response)\n",
    "plt.show()\n",
    "\n",
    "samplerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "samplerateも同じ44100なので、単純に音源にこれをたたみこんでやれば、教会で歌うMy Wayになるはず。\n",
    "\n",
    "ただし、6秒もの残響の計算は時間がかかりすぎるので、はじめの1秒だけ使うことにする。\n",
    "(PCが速い人は、全部使って試してみてもいい)\n",
    "\n",
    "(フーリエ変換を使って畳み込み積分を爆速で計算する方法があるが、numpyはどうもそれを使っていないようだ。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song = np.convolve(mono, response[:44100], mode='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(song, rate=samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原曲と聴きくらべ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(mono, rate=samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scipyにはFFT(高速フーリエ変換)を使った畳み込みがあった。 https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.fftconvolve.html#scipy.signal.fftconvolve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "fftsong = scipy.signal.fftconvolve(mono, response, mode='same')\n",
    "Audio(fftsong, rate=samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "畳み込み積分は、音響学だけでなく、様々な分野で非常に重要である。\n",
    "\n",
    "* 光学におけるブレやボケの計算\n",
    "* 電気回路における信号伝達\n",
    "* 桁数の非常に大きな数同士のかけ算\n",
    "* 信号へのノイズの重畳\n",
    "* 量子力学における伝搬関数\n",
    "* 液体論における積分方程式\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 宿題2\n",
    "\n",
    "上で読みこんだmono (MyWay.mp3のモノラル音声)を使って、以下の処理を行うプログラムを書いて下さい。(できる範囲で)\n",
    "\n",
    "1. 逆再生\n",
    "2. 倍速再生 (データを1つおきに間引く。音が1オクターブ高くなる)\n",
    "3. もとの音に0.2秒ずらした音を重ねて再生\n",
    "4. 倍速再生 (音が高くならない)\n",
    "5. 最大値、最小値、平均値を求める\n",
    "6. 教会のインパルス応答を逆再生にして、monoに畳み込んで、変な残響をつくる\n",
    "\n",
    "----\n",
    "\n",
    "2番、誰かが話している時に、その人の声を0.2秒遅れで再生して聞かせると、その人は話が続けられなくなる、という研究があります。(https://srad.jp/story/12/03/04/1812249/ 2012年イグ・ノーベル賞https://scienceportal.jst.go.jp/news/newsflash_review/newsflash/2012/10/20121003_01.html)\n",
    "\n",
    "----\n",
    "\n",
    "4番、音が高くならないように高速再生する方法はいくつかありますが、一番簡単なのは、\n",
    "\n",
    "* まず音楽を0.1秒ぐらいの長さのパケットに細分する。\n",
    "* パケットを1つおきにえらんでつなぎなおす。\n",
    "\n",
    "という方法です。例えば、元のデータが`[1,2,3,4,5,6,7,8,9,10, ... ,997,998,999,1000]`だとして、これを4データずつのパケットに分割し、`[1,2,3,4] [5,6,7,8] [9,10,11,12] ... [997 998 999 1000]`として、それらからひとつおきにえらんできてつないで`[1,2,3,4,9,10,11,12,17,18,19,20, ... ,993,994,995,996]`のようにするわけです。\n",
    "\n",
    "実際のプログラム中では、元の音楽データ(mono, 20秒、882000データ)の半分の長さの0配列をあらかじめ準備し、そこにmonoの断片を書きこんでいきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half = np.zeros(44100*10)\n",
    "# 0.1秒分のデータ長\n",
    "packetlen = 4410\n",
    "packetnum = 100\n",
    "# 最初の0.1秒をmonoからhalfに書き移す\n",
    "half[0:packetlen] = mono[0:packetlen]\n",
    "# 次の0.1秒\n",
    "half[packetlen:packetlen*2] = mono[packetlen*2:packetlen*2+packetlen]\n",
    "# これをpacketnum回くりかえす (for文を使う)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "なお、ゆっくり再生したい場合は逆に、同じ断片を2個繰りかえして`[1,2,3,4,1,2,3,4,5,6,7,8,5,6,7,8,...]`のようにつなぎます。\n",
    "\n",
    "2と4の技術を組みあわせると、再生速度がもとのままで、音だけ1オクターブ下げる、ということも可能です。(ボイスチェンジャー)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
