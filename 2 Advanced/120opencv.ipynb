{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "120opencv.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vitroid/PythonTutorials/blob/2020m0/2%20Advanced/120opencv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bQ5lSNHmCD_",
        "colab_type": "text"
      },
      "source": [
        "# OpenCVでとにかく何か表示してみよう。\n",
        "\n",
        "> OpenCV（オープンシーヴィ、英語: Open Source Computer Vision Library）とはインテルが開発・公開したオープンソースのコンピュータビジョン向けライブラリ[1]。2009年にWillow Garage（ウィロー・ガレージ）に開発が移管された後、2015年現在はItseezがメンテナンスを行なっている[2]。なお、2016年5月26日にインテルがItseezを買収することが発表された。[Wikipedia](https://en.wikipedia.org/wiki/OpenCV)\n",
        "\n",
        "> OpenCV (Open Source Computer Vision) is a library of programming functions mainly aimed at real-time computer vision.[2] Originally developed by Intel, it was later supported by Willow Garage and is now maintained by Itseez.[1] The library is cross-platform and free for use under the open-source BSD license. [Wikipedia](https://en.wikipedia.org/wiki/OpenCV)\n",
        "\n",
        "たぶん今のPCならカメラを内蔵しているだろうから、カメラから直接とりこむのが一番てっとりばやい。\n",
        "\n",
        "Almost all note PC has a camera for Skyping.  We utilize it to capture the sample image.\n",
        "\n",
        "(Macの場合、セキュリティの確認ダイアログが表示される)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF2ckoPRmQ3s",
        "colab_type": "text"
      },
      "source": [
        "## Google ColabでのOpenCVの利用\n",
        "\n",
        "Google ColabでOpenCVを使う場合、カメラは手許にあるのに処理系がクラウド上にあるため、その間のデータ転送が大きな問題となる。実際、動画をリアルタイムで処理するようなことはたぶんできない。リアルタイムで本格的な画像処理を行う場合は、手許のPython開発環境(Anacondaなど)を使う必要がある。\n",
        "\n",
        "ここでは、静止画に対する画像処理のみを紹介する。\n",
        "\n",
        "Google Colabが提供している、カメラ撮影のコードサンプル。\n",
        "\n",
        "* https://colab.research.google.com/drive/1tbAeRge6KKgCYdC6ihDrsl80aRYoVOMa\n",
        "* 動画は手許のコンピュータ上で表示し、Colabには送られない。そのため、ほぼリアルタイムで動画が表示される。\n",
        "* 画面をクリックすると、その瞬間の画像がColab上に保存される。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkdV4mF3m52y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import HTML, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "VIDEO_HTML = \"\"\"\n",
        "<video autoplay\n",
        " width=800 height=600></video>\n",
        "<script>\n",
        "var video = document.querySelector('video')\n",
        "navigator.mediaDevices.getUserMedia({ video: true })\n",
        "  .then(stream=> video.srcObject = stream)\n",
        "  \n",
        "var data = new Promise(resolve=>{\n",
        "  video.onclick = ()=>{\n",
        "    var canvas = document.createElement('canvas')\n",
        "    var [w,h] = [video.offsetWidth, video.offsetHeight]\n",
        "    canvas.width = w\n",
        "    canvas.height = h\n",
        "    canvas.getContext('2d')\n",
        "          .drawImage(video, 0, 0, w, h)\n",
        "    video.srcObject.getVideoTracks()[0].stop()\n",
        "    video.replaceWith(canvas)\n",
        "    resolve(canvas.toDataURL('image/jpeg', %f))\n",
        "  }\n",
        "})\n",
        "</script>\n",
        "\"\"\"\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  display(HTML(VIDEO_HTML % quality))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return len(binary)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doZhP7M4wVdu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Colab上に保存する。\n",
        "take_photo(\"photo.jpg\")\n",
        "# Google Drive内に保存したいなら\n",
        "# take_photo(\"/content/drive/My Drive/photo.jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f5ubt-UtWiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OpenCVの画像をColabで表示するための関数を準備しておく。\n",
        "def Show(image):\n",
        "    # 画像操作ライブラリ\n",
        "    from PIL import Image \n",
        "\n",
        "    if len(image.shape) == 2:\n",
        "        # 白黒画像\n",
        "        display(Image.fromarray(image[:,:]))\n",
        "    else:\n",
        "        # 画像はnumpy arrayの形になっていて、image[行, 列, 色]\n",
        "        # OpenCVの色はBGR順だが通常はRGB順なので、displayする時に順番を入れかえる。\n",
        "        # 以下の例ではdisplayは使わないので、色順を気にしなくていい\n",
        "        display(Image.fromarray(image[:,:,::-1]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gQ8boiImCEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OpenCVライブラリを読みこむ。\n",
        "import cv2\n",
        "\n",
        "# カメラからの直接とりこみができないので、colab上の写真ファイルで代用する。\n",
        "\n",
        "#   # Device ID of the camera would be 0\n",
        "#   # カメラのデバイス番号は0番になっていることが多い。\n",
        "#   # デバイス番号の代わりに動画ファイルを指定することもできる。\n",
        "#   camera = cv2.VideoCapture(0)\n",
        "#   \n",
        "#   # Capture a frame from the camera.\n",
        "#   # カメラから1フレーム読みこむ。retがFalseになったら読み損ねている。\n",
        "#   ret, image = camera.read()\n",
        "\n",
        "image = cv2.imread(\"photo.jpg\")\n",
        "\n",
        "# 画像の大きさを400x300に縮小。\n",
        "image = cv2.resize(image, (400,300))\n",
        "\n",
        "Show(image)\n",
        "\n",
        "# 画像のサイズを見る。\n",
        "print(image.shape)\n",
        "\n",
        "#   camera.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOQenEB-mCEg",
        "colab_type": "text"
      },
      "source": [
        "imageの中身に注目して下さい。整数値の三つ組がたくさんはいった,3次元のnumpy arrayになっています。\n",
        "3つ組の数字はRGB(三原色)を表現していて、写真の画素一つ一つの色がすべて含まれています。\n",
        "それが行ごとにまとめられ、すべての行をまとめたものが1枚の写真になります。\n",
        "つまり、numpyのarrayの操作さえ知っていれば、写真を自由に操作できる、ということになります。\n",
        "\n",
        "See the content of the `image` variable. It is a three-dimensional numpy array of integers.\n",
        "The innermost triplets express the intensities of the three primitive colors, blue, green, and red, at a single pixel.\n",
        "Pixels are bundled to make a row, and the rows are budled to make the whole image.\n",
        "That is, if you know how to access and modify the numpy array, you can also process the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7II3-yyKmCEj",
        "colab_type": "text"
      },
      "source": [
        "`row`行目のピクセルの色は、`image[row]`あるいは`image[row,:,:]`で参照できます。(numpyでは、\"：\"は全要素を表しますから、この表記はrow行目、全列、全色を指し示しています。)\n",
        "\n",
        "Colors of the pixels at the `row` are referred to as `image[row]` or `image[row,:,:]`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e01T8ahymCEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image[100,:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQJ10GRAmCEu",
        "colab_type": "text"
      },
      "source": [
        "`row`行目、`col`列目のピクセルの色は、`image[row,col]`あるいは`image[row,col,:]`で参照できます。\n",
        "\n",
        "Color of the pixel at (`row`, `col`) is referred to as `image[row,col]` or `image[row,col,:]`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmvzViVJmCEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image[100,200,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i9wF7ZdmCFK",
        "colab_type": "text"
      },
      "source": [
        "`row`行目、`col`列目のピクセルの赤色の強度は、`image[row,col,2]`で参照できます。色の順番はRGBではなくBGR(0=Blue, 1=Green, 2=Red)です。\n",
        "\n",
        "The red strength of the pixel at (`row`, `col`) is referred to as `image[row,col,2]`. Note that color order is not RGB but BGR (blue is 0, green is 1, red is 2)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "8XTT9DMQmCFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image[100,200,2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA68d62ZmCFP",
        "colab_type": "text"
      },
      "source": [
        "画像は`imwrite()`関数を使って保存できます。保存先はColab上となります。\n",
        "\n",
        "The obtained image can be saved with `imwrite()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJEla0xzmCFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv2.imwrite(\"test.jpg\", image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsNj8l1CmCFY",
        "colab_type": "text"
      },
      "source": [
        "Google Colabで動画の連続処理はうまく機能しません。以下の説明はJupyterなどのローカル開発環境用です。\n",
        "\n",
        "> 上の例では1枚の写真が得られるだけですが、これをくりかえせば、ムービーになります。\n",
        "動画のウィンドウ上で何かキーを押せばプログラムが終わるようになっています。\n",
        "画像解像度が高すぎる場合は、resize関数で小さくして下さい。\n",
        "\n",
        "> In the example above, only one image is obtained. If you repeat the process with a loop, you get a movie.\n",
        "If the picture size is too large to be displayed, use `resize()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A9cfV1QmCFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "camera = cv2.VideoCapture(0)  #Device ID of the camera would be 0\n",
        "\n",
        "while cv2.waitKey(1) < 0:\n",
        "    ret, image = camera.read()\n",
        "    image = cv2.resize(image, (640,360))\n",
        "    cv2.imshow(\"Hello!\", image)\n",
        "\n",
        "#Close all the windows.  \n",
        "cv2.destroyAllWindows()\n",
        "# cv2.waitKey(1)\n",
        "camera.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdY75xHLmCFl",
        "colab_type": "text"
      },
      "source": [
        "## 簡単な画像処理\n",
        "色の明るさは0〜255の整数で表現されていますから、色調を完全に反転させるには、255から引きます。\n",
        "\n",
        "カメラからとりこんだ画像を、ウィンドウに表示する前に、処理をすれば、処理後の画像を見ることができます。\n",
        "もちろん、2つウィンドウをひらいて、両方見比べることも簡単です。\n",
        "\n",
        "Color intensities are expressed by the integer number between 0 (dark) and 255 (bright). Therefore, if you want to invert the colors, subtract them from 255.\n",
        "\n",
        "In the following sample, the original and inverted images are shown in a different window."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUoC1eDimCFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reversed_image = 255 - image #reverse the colors (numpy operation)\n",
        "Show(image)\n",
        "Show(reversed_image)  #Show the reversed image\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0ixlG1vmCF1",
        "colab_type": "text"
      },
      "source": [
        "赤だけを反転するには? ここでもnumpyのarray操作が使えます。\n",
        "\n",
        "Can we then invert the red component only?  Numpy is useful for such an operation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc5DB9ndmCF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image2 = image.copy() #firstly make the copy of the image\n",
        "image2[:,:,2] = 255 - image2[:,:,2]  #Color order in OpenCV is not RGB but BGR.\n",
        "\n",
        "Show(image2)  #Show the reversed image\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDDonTqSmCF4",
        "colab_type": "text"
      },
      "source": [
        "上下を入れかえたいなら、行を反転すればいいのです。\n",
        "\n",
        "If you want to make the image upside-down, just invert the order of image rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlT1N-BXmCF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "upsidedown = image[::-1,:,:] \n",
        "Show(upsidedown)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1UhYDDJvE0r",
        "colab_type": "text"
      },
      "source": [
        "RGBの1つだけを表示すると、白黒になります。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XML_oCoGvQBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Show(image[:,:,0])\n",
        "Show(image[:,:,1])\n",
        "Show(image[:,:,2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25fdYHEWmCGC",
        "colab_type": "text"
      },
      "source": [
        "## 宿題1\n",
        "右半分を反転して左半分に表示するようにしてみましょう。\n",
        "\n",
        "Fold the right half onto the left half of the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqTf1nrlmCGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pHaYAzjmCGJ",
        "colab_type": "text"
      },
      "source": [
        "## 少し高度な画像処理 More tricks\n",
        "瞬間瞬間の画像を加工するのではなく、時間変化をとらえてみましょう。以下の例では、直前の画像をlastimage変数に保存しておき、absdiff関数で画像の差分を作ります。\n",
        "\n",
        "Instead of processing an instantaneous image, let us process the difference.  In the following example, the captured image is stored in `lastimage` and compare it with the new capture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMXMLFljmCGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "take_photo(\"first.jpg\")\n",
        "take_photo(\"second.jpg\")\n",
        "\n",
        "first  = cv2.imread(\"first.jpg\")\n",
        "second = cv2.imread(\"second.jpg\")\n",
        "diff = cv2.absdiff(first, second)\n",
        "Show(255 - diff)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz9kEb1emCGR",
        "colab_type": "text"
      },
      "source": [
        "爬虫類や両生類は、動いているものしか見えないと言います。たぶん彼らの見ている世界はこんな感じなのでしょう。\n",
        "\n",
        "It is said that reptiles and amphibians only see the moving things. Perhaps they are looking the world like this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7kAjTUHmCGS",
        "colab_type": "text"
      },
      "source": [
        "OpenCVの関数で、輪郭抽出するCannyを使ってみましょう。これは動きを検出するわけではなく、静止画1枚から輪郭を見つけます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXIkIPWAmCGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "diff = cv2.Canny(image, 100, 200) #min and max\n",
        "Show(diff)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJJxmsTCmCGW",
        "colab_type": "text"
      },
      "source": [
        "面白いのでもっと遊んでみます。輪郭線をもとの画像に重ねてみます。世界がアニメ風になります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQMOEpimmCGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "diff = cv2.Canny(image, 10, 200) #min and max\n",
        "\n",
        "# imageを書換えたくないので、コピーする。\n",
        "playground = image.copy()\n",
        "# diffの値が0でない(=白)の部分だけ、画素を0にする。\n",
        "playground[diff>0] = 0  \n",
        "Show(playground)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A8F_uhgmCGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlf4SK93mCGm",
        "colab_type": "text"
      },
      "source": [
        "## 高度な画像処理 Advanced image processing\n",
        "\n",
        "以下は残念ながらColabでは実験できません。\n",
        "\n",
        "OpenCVは最先端の画像処理ライブラリなので、単なる画像の編集以上のことができます。私たちは画像処理の専門家ではないので、技術的な内容まではよくわかりませんが、とにかく利用することならできます。\n",
        "\n",
        "次の例では、Background Subtractionという技術を使い、背景と動いている物体を区別して、動きがあった部分だけを切り抜きます。\n",
        "\n",
        "https://docs.opencv.org/3.4/db/d5c/tutorial_py_bg_subtraction.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNiYlV6HmCGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "cap = cv2.VideoCapture(0)\n",
        "# BackgroundSubtractorを作成。いつものように中身はブラックボックス\n",
        "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "while cv2.waitKey(1) < 0:\n",
        "    ret, image = camera.read()\n",
        "    image = cv2.resize(image, (640,360))\n",
        "    # BackgroundSubtractorに画像を渡すと、マスクを生成する。\n",
        "    fgmask = fgbg.apply(image)\n",
        "    cv2.imshow(\"Image\", image)\n",
        "    cv2.imshow(\"Mask\", fgmask)\n",
        "\n",
        "#Close all the windows.  \n",
        "cv2.destroyAllWindows()\n",
        "camera.release()\n",
        "cv2.waitKey(1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMVxFC78mCGp",
        "colab_type": "text"
      },
      "source": [
        "マスクというのは、画像のなかで注目する部分だけを白にした、白黒画像のことです。マスクを使うと、画像を切り抜けます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7XXa-uGmCGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from time import sleep\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "# BackgroundSubtractorを作成。いつものように中身はブラックボックス\n",
        "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "\n",
        "while cv2.waitKey(1) < 0:\n",
        "    ret, image = camera.read()\n",
        "    image = cv2.resize(image, (640,360))\n",
        "    # BackgroundSubtractorに画像を渡すと、マスクを生成する。\n",
        "    fgmask = fgbg.apply(image)\n",
        "    \n",
        "    # fgmaskの値が0の部分だけ、画像も0にする\n",
        "    image[fgmask==0] = 0\n",
        "    cv2.imshow(\"Masked Image\", image)\n",
        "    # 0.1秒待たせ、わざとコマ送りにします。\n",
        "    sleep(0.1)\n",
        "\n",
        "#Close all the windows.  \n",
        "cv2.destroyAllWindows()\n",
        "camera.release()\n",
        "cv2.waitKey(1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SguxcCgLmCGs",
        "colab_type": "text"
      },
      "source": [
        "動いた部分だけを上書きしていくと?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqDiaw1kmCGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from time import sleep\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "# BackgroundSubtractorを作成。いつものように中身はブラックボックス\n",
        "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "# 最初のコマをfirstに入れておきます。\n",
        "ret, first = camera.read()\n",
        "first = cv2.resize(first, (640,360))\n",
        "\n",
        "while cv2.waitKey(1) < 0:\n",
        "    ret, image = camera.read()\n",
        "    image = cv2.resize(image, (640,360))\n",
        "    # BackgroundSubtractorに画像を渡すと、マスクを生成する。\n",
        "    fgmask = fgbg.apply(image)\n",
        "    \n",
        "    # fgmaskの値が0でない部分だけ、imageの内容をfirstに上書きする\n",
        "    first[fgmask>0] = image[fgmask>0]\n",
        "    # 動いた部分だけが書き加えられます。\n",
        "    # 左右は反転したほうがわかりやすい。\n",
        "    cv2.imshow(\"Canvas\", first[:, ::-1, :])\n",
        "    # 0.1秒待たせ、わざとコマ送りにします。\n",
        "    sleep(0.1)\n",
        "\n",
        "#Close all the windows.  \n",
        "cv2.destroyAllWindows()\n",
        "camera.release()\n",
        "cv2.waitKey(1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2ge5PBXmCGw",
        "colab_type": "text"
      },
      "source": [
        "## 高度な画像処理 Advanced image processing 2 (Colab)\n",
        "\n",
        "最近のカメラのように、映像の中に顔を見付けだす実験をやってみます。といっても、自分ではその方法が見当もつかないので、Googleに頼ります。\n",
        "\n",
        "Googleで\"OpenCV python face detection\" \"OpenCV python 顔認識\" などのキーワードで検索すると、10行程度のコードを書くだけで顔認識してくれることがわかります。今回は、[http://qiita.com/wwacky/items/98d8be2844fa1b778323](http://qiita.com/wwacky/items/98d8be2844fa1b778323) のコードを読み、上で書いたプログラムに組み込んで、動画からリアルタイムで顔を認識するようにしてみましょう。\n",
        "\n",
        "Since OpenCV is a state-of-the-art image processing library, it can do more than just editing images. We are not experts in image processing, so we do not know the technical content well, but we can do it anyway.\n",
        "\n",
        "Let us try to detect the faces in the captured image like a recent digital cameras and smart phones.\n",
        "\n",
        "Giving the keywords such as \"OpenCV python face recognition\" on Google, you can get the codes for face recognition.  They are only 10 lines of Python.  For this time, I read the code of [http://qiita.com/wwacky/items/98d8be2844fa1b778323] (http://qiita.com/wwacky/items/98d8be2844fa1b778323) and incorporate it into the program written above.\n",
        "\n",
        "コードをそのままコピーするのははばかられるので、要点だけ書くと、\n",
        "\n",
        "Essential parts of the code are following.\n",
        "\n",
        "```python\n",
        "#HAAR分類器の顔検出用の特徴量。顔らしさの指標。これはOpenCVのサンプルコードに付属しているものをそのまま利用。\n",
        "#Feature collection of the faces for HAAR classifier. It is contained in the sample code for OpenCV.\n",
        "cascade_path = \"haarcascade_frontalface_alt.xml\"\n",
        "\n",
        "#グレースケール変換。モノクロ画像で認識するらしい。\n",
        "#この部分はOpenCV3で書き方が変わったらしい。\n",
        "#It converts a color image into a gray image.\n",
        "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "#カスケード分類器の特徴量を取得する。ループの外で一回だけ実行するだけでよさそう。\n",
        "#Initializer for the feature detector.  Must be executed only once (outside the loop)\n",
        "cascade = cv2.CascadeClassifier(cascade_path)\n",
        "\n",
        "#物体認識（顔認識）の実行。facerectには、顔を含む領域の長方形(複数)が入る。\n",
        "#Feature detection. It returns the list of rectangles in which faces are detected.\n",
        "facerect = cascade.detectMultiScale(image_gray, scaleFactor=1.1, minNeighbors=1, minSize=(1, 1))\n",
        "\n",
        "#imageに長方形を描きこむ関数。\n",
        "#It draws a rectangle on the given image.\n",
        "cv2.rectangle(image, tuple(rect[0:2]),tuple(rect[0:2]+rect[2:4]), color, thickness=2)\n",
        "```\n",
        "\n",
        "これらを、上のコードに埋めこみます。\n",
        "\n",
        "Let us embed them in our program."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaRPT2IrmCGy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install pnslib\n",
        "!pip install git+git://github.com/PnS2019/pnslib.git\n",
        "\n",
        "from pnslib import utils\n",
        "\n",
        "#HAAR分類器の顔検出用の特徴量。顔らしさの指標。これはサンプルコードに付属しているものをそのまま利用。\n",
        "# https://colab.research.google.com/drive/1CmZwkzrkap3nvPvUbuYy3NBZPe5jYZls\n",
        "face_cascade = cv2.CascadeClassifier(\n",
        "    utils.get_haarcascade_path('haarcascade_frontalface_default.xml'))\n",
        "\n",
        "image = cv2.imread(\"photo.jpg\")\n",
        "\n",
        "#グレースケール変換。モノクロ画像で認識するらしい。\n",
        "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "#物体認識（顔認識）の実行。facerectには、顔を含む領域の長方形(複数)が入る。\n",
        "facerect = face_cascade.detectMultiScale(image_gray, scaleFactor=1.3, minNeighbors=2)\n",
        "\n",
        "for (x,y,w,h) in facerect:\n",
        "    #imageに長方形を描きこむ関数。\n",
        "    cv2.rectangle(image, (x,y), (x+w,y+h), (0,255,0), thickness=2)\n",
        "\n",
        "Show(image)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XbN2JIbmCG7",
        "colab_type": "text"
      },
      "source": [
        "顔をモザイクにします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5e8b2-8mCG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install pnslib\n",
        "!pip install git+git://github.com/PnS2019/pnslib.git\n",
        "\n",
        "from pnslib import utils\n",
        "\n",
        "#HAAR分類器の顔検出用の特徴量。顔らしさの指標。これはサンプルコードに付属しているものをそのまま利用。\n",
        "# https://colab.research.google.com/drive/1CmZwkzrkap3nvPvUbuYy3NBZPe5jYZls\n",
        "face_cascade = cv2.CascadeClassifier(\n",
        "    utils.get_haarcascade_path('haarcascade_frontalface_default.xml'))\n",
        "\n",
        "image = cv2.imread(\"photo.jpg\")\n",
        "\n",
        "#グレースケール変換。モノクロ画像で認識するらしい。\n",
        "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "#物体認識（顔認識）の実行。facerectには、顔を含む領域の長方形(複数)が入る。\n",
        "facerect = face_cascade.detectMultiScale(image_gray, scaleFactor=1.3, minNeighbors=2)\n",
        "\n",
        "for (x,y,w,h) in facerect:\n",
        "    # 四角の中だけ切りだす。\n",
        "    square = image[y:y+h,x:x+w]\n",
        "    # 6x6 pixelに縮小する。\n",
        "    small = cv2.resize(square, (6,6))\n",
        "    # もとの大きさに拡大する。\n",
        "    reduced = cv2.resize(small, (w,h), interpolation=cv2.INTER_NEAREST)\n",
        "    # imageに戻す。\n",
        "    image[y:y+h,x:x+w] = reduced\n",
        "\n",
        "Show(image)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_jS3Rxy2Hvk",
        "colab_type": "text"
      },
      "source": [
        "残念ながら、Colab上ではリアルタイムで動画に画像処理を加えることはできませんが、てもとの開発環境で実行すれば、リアルタイムでモザイクを入れるプログラムも簡単に書けます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1C-LVi-mCG_",
        "colab_type": "text"
      },
      "source": [
        "こういうプログラムは何に使えるの? 何でしょうね。例えば、\n",
        "\n",
        "* 顔認識は、顕微鏡写真から、細胞の核の個数を数えたりできるでしょう。その場合、特徴量ファイルを細胞核用に準備する必要はあります。\n",
        "* 動きの検出は、遅い反応や、まれにしかおこらない現象を監視するのに使えます。もちろん、防犯カメラにも。\n",
        "\n",
        "OpenCVのすべての機能はとても紹介しきれませんが、画像処理を専門としている研究者たちが、OpenCVを使って新しい画像処理方法を見付けたり、逆に新しいアルゴリズムをOpenCVに追加したりしています。OpenCVを使えれば、それらの最新の技術を自分の研究にとりこんでいけるのです。\n",
        "\n",
        "\n",
        "How can we use them for our research?\n",
        "\n",
        "* Face recognition can count the number of cell nuclei from the photomicrograph. In that case, you need to prepare the feature file for the cell nucleus.\n",
        "* Motion detection can be used to monitor slow reactions or rare phenomena. Of course, also for security cameras.\n",
        "\n",
        "Researchers who specialize in image processing use OpenCV to find a new image processing method and add new algorithms to OpenCV. With OpenCV, you can incorporate those latest technologies into your own research."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1XyVyYpmCHA",
        "colab_type": "text"
      },
      "source": [
        "## 間にあわなかった物ども\n",
        "\n",
        "[OpenCVの機能リスト](https://docs.opencv.org/3.0-beta/modules/refman.html)を見ると、ほかにも面白そうな機能がたくさんありますね。まだまだ修行が必要です。\n",
        "\n",
        "* ビデオスタビライザー\n",
        "* 超解像\n",
        "* QRコードの認識\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lHX9OqYmCHA",
        "colab_type": "text"
      },
      "source": [
        "## 宿題2\n",
        "\n",
        "未定。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCwSg0jHmCHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}