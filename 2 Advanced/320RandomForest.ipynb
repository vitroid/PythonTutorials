{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "320RandomForest.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vitroid/PythonTutorials/blob/master/2%20Advanced/320RandomForest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcPXmkyXy5xP"
      },
      "source": [
        "# 教師あり学習の例\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbyLV3U1y5xR"
      },
      "source": [
        "## 決定木による分類\n",
        "\n",
        "(Pythonデータサイエンスハンドブックp.423)\n",
        "\n",
        "次のような2次元のデータを考える。データの種類によって4つの色が割りあてられている。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMbrrI-qy5xT"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "X,y = make_blobs(n_samples=300, centers=4, random_state=0, cluster_std=1.0) #散布データを生成する便利な関数\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='rainbow')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsBoDq9Oy5xb"
      },
      "source": [
        "上の例では、Xに各点の座標が、yには色(0〜3)が入っている。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rERsdcIRy5xd"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8e3-RZUy5xi"
      },
      "source": [
        "これらの点の集合に対し、境界線を引きたい。人間にやらせれば簡単に目分量で引くだろうが、これを機械にやらせたい。\n",
        "\n",
        "最も安易な方法として、水平あるいは垂直な線で全体をおおまかに二分する。分割に際しては、色をランダムにひとつ選び、その色と、他の色の峻別が最大になるような位置で分ける。(多数決原理)\n",
        "\n",
        "(言葉で書くと簡単そうだが、自分で書くとけっこう面倒臭い。水平に境界をひくのが良いか、垂直のほうが良いか、どの色を選ぶべきかなど、うまくやらないと境界線が決まらなかったりする)\n",
        "\n",
        "指定された回数に達するか、領域に1つの色しか含まれなくなるまでこれを繰りかえす。\n",
        "\n",
        "ここでは、Scikit-learnに含まれるDecisionTreeClassifier(決定木分類器)を使うことにする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5qvPWrUy5xj"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "tree = DecisionTreeClassifier().fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgwIlQWFy5xm"
      },
      "source": [
        "以下の関数を使って、二分した結果を表示する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LZKVMyey5xn"
      },
      "source": [
        "def visualize_classifier(model, X, y, ax=None, cmap='rainbow'):\n",
        "    ax = ax or plt.gca()\n",
        "    # 訓練データをプロット\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=cmap, clim=(y.min(), y.max()), zorder=3)\n",
        "    ax.axis('tight')\n",
        "    ax.axis('off')\n",
        "    xlim = ax.get_xlim()\n",
        "    ylim = ax.get_ylim()\n",
        "\n",
        "    # 推定値へのあてはめ\n",
        "    model.fit(X, y)\n",
        "    xx,yy = np.meshgrid(np.linspace(*xlim, num=200), np.linspace(*ylim, num=200))\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
        "\n",
        "    # 色分け表示\n",
        "    n_classes = len(np.unique(y))\n",
        "    contours = ax.contourf(xx, yy, Z, alpha=0.3,\n",
        "                          levels=np.arange(n_classes+1) - 0.5,\n",
        "                          cmap=cmap, #clim=(y.min(), y.max()),\n",
        "                           zorder=1)\n",
        "    ax.set(xlim=xlim, ylim=ylim)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPIW2SQNy5xr"
      },
      "source": [
        "visualize_classifier(DecisionTreeClassifier(max_depth=1), X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr3qB34gy5xu"
      },
      "source": [
        "visualize_classifier(DecisionTreeClassifier(max_depth=2), X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CcTrsu8y5xx"
      },
      "source": [
        "visualize_classifier(DecisionTreeClassifier(max_depth=3), X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktlEn1hDy5xz"
      },
      "source": [
        "visualize_classifier(DecisionTreeClassifier(max_depth=4), X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JseWnTZ-y5x2"
      },
      "source": [
        "こんな風に、データをつぎつぎに二分して細分していくデータ構造をツリーと呼ぶ。(この絵では木には見えないが)\n",
        "\n",
        "これを見ると、「なんと回りくどい手順だ。もっと直観的に境界線を引けそうなのに」と思うかもしれない。しかし、上の例は2次元データだから画面上で境界が明らかに見えるが、例えばあとででてくるような64次元データになると、直感など何の役にも立たないことは容易に想像できる。機械学習の強みは、人間の直感をはるかに超えた多次元データであってもそれなりに境界を自動的に決められる点にある。\n",
        "\n",
        "上の例では、4段階まで分割を行い、それなりに良い境界線を得た。調子にのってこのまま完全に分類ができるまで細分していくとどうなるか。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy2NWsmqy5x3"
      },
      "source": [
        "visualize_classifier(DecisionTreeClassifier(), X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X67V3Ui7y5x5"
      },
      "source": [
        "境界線が不自然に複雑になってしまうのがわかると思う。これはいわゆる「過学習」である。(以前、多項式フィッティングで、不必要に複雑な曲線が得られたケースを思いだしてほしい)\n",
        "\n",
        "過学習に至ると、与えられた訓練データに対しては非常によいフィッティング性能を示すが、未知データへのあてはめで失敗する可能性が高くなる(例えば、上の図に見られる赤の小領域など)\n",
        "\n",
        "決定木分類器はこのように過学習に至りやすい。この弱点を補うために考えられたのが次のランダムフォレスト法である。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiZZxbX0y5x6"
      },
      "source": [
        "### ランダムフォレスト法\n",
        "決定木分類器において、縦割りや横割りの順序、選択する色をランダムに変化させると、境界線はその都度変化する。それらを集計し、統計的に境界線を決定するのがランダムフォレスト法である。(フォレスト「森」という名前は木をたくさん生成するところから来ていると思われる)\n",
        "上のデータに対し、ランダムフォレスト法を適用すると、かなりそれらしい境界線が得られる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MAZ_ioiy5x6"
      },
      "source": [
        "from sklearn.ensemble        import RandomForestClassifier\n",
        "\n",
        "visualize_classifier(RandomForestClassifier(n_estimators=100), X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgFlpkCjy5x9"
      },
      "source": [
        "この結果では、一見すると決定木分類器の結果とそれほど見た目が変わらないので、ランダムフォレスト法の威力を実感できないかもしれない。そこで、もっと実用的な問題に挑戦する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE0x28nSy5x9"
      },
      "source": [
        "### ランダムフォレスト法による文字分類\n",
        "\n",
        "手書き文字を学習させ、分類器を作る。\n",
        "\n",
        "手書き文字は8x8ピクセルのグレースケール画像で、それぞれの文字のデータが教師データとして与えられている。\n",
        "\n",
        "64個の数値の列から、文字を割りだすと考えると、これは64次元での分類問題と言える。\n",
        "\n",
        "学習用データを表示してみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S-SKidMy5x-"
      },
      "source": [
        "# taken from Python Data Science handbook\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()\n",
        "\n",
        "# 画像データの表示\n",
        "fig, ax = plt.subplots(8, 8, figsize=(6, 6))\n",
        "fig.subplots_adjust(left=0,right=1, bottom=0,top=1,hspace=0.05,wspace=0.05)\n",
        "for i, axi in enumerate(ax.flat):\n",
        "    axi.imshow(digits.images[i], cmap='binary')\n",
        "    axi.text(0,7,str(digits.target[i]))\n",
        "    axi.set(xticks=[], yticks=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3PCI8KXy5yC"
      },
      "source": [
        "過学習かどうかを判定できるように、データを2つに分ける。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE2WtncKy5yD"
      },
      "source": [
        "# 学習用データとテストデータの分割\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(digits.data, digits.target, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S53xOiSky5yF"
      },
      "source": [
        "学習用データを使って、ランダムフォレスト分類器を訓練する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EX2c9yQy5yG"
      },
      "source": [
        "from sklearn.ensemble        import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=1000)\n",
        "model.fit(Xtrain, ytrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJLnAo6jy5yJ"
      },
      "source": [
        "それを使って、未知データの推定を行う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wISkLEssy5yJ"
      },
      "source": [
        "ypred = model.predict(Xtest)\n",
        "\n",
        "# print(digits.images)\n",
        "# print(Xtest)\n",
        "# 画像データの表示\n",
        "fig, ax = plt.subplots(12, 12, figsize=(6, 6))\n",
        "fig.subplots_adjust(left=0,right=1, bottom=0,top=1,hspace=0.05,wspace=0.05)\n",
        "for i, axi in enumerate(ax.flat):\n",
        "    axi.set(xticks=[], yticks=[])\n",
        "\n",
        "    if ypred[i] != ytest[i]:\n",
        "        axi.text(0,7,str(ypred[i]), color='red')\n",
        "        axi.imshow((Xtest[i]).reshape(8,8), cmap='Reds')\n",
        "    else:\n",
        "        axi.imshow(Xtest[i].reshape(8,8), cmap='binary')\n",
        "\n",
        "\n",
        "\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(ypred, ytest))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e608JzPOy5yL"
      },
      "source": [
        "144個のテストデータで4つを読み違えたので、正答率は97%である。(読み間違えた文字は人間でも分類が難しく、計算機に同情する)\n",
        "\n",
        "プログラムする人が何の工夫もすることなく、全自動でデータを学習させるだけで、これだけ分類できるのはなかなか大したものと言えるのではないだろうか。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 応用1\n",
        "\n",
        "名前から、性別を推定できるかどうかを見てみましょう。\n",
        "\n",
        "世界中の名前のデータセットが公開されていて、pythonで簡単にアクセスできます。\n",
        "\n",
        "元データはこちら: https://github.com/philipperemy/name-dataset"
      ],
      "metadata": {
        "id": "yvYC-ey9SjwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install names-dataset"
      ],
      "metadata": {
        "id": "vISOawV4TAe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "まずは、データセットの中身を覗いてみます。"
      ],
      "metadata": {
        "id": "CzPuH9ZETXII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from names_dataset import NameDataset, NameWrapper\n",
        "nd = NameDataset()\n",
        "# 日本人の名前の上位1000000個をとってくる\n",
        "data = nd.get_top_names(n=1000000, country_alpha2='JP')\n",
        "data"
      ],
      "metadata": {
        "id": "lh6a1ZBVTbFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "漢字とアルファベットの名前が混在しているので、アルファベットに限定します。(日本人なら、名前を聞くだけでだいたい聞きわけられると想定)\n",
        "\n"
      ],
      "metadata": {
        "id": "86YDynxPUa9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"JP\"].keys()"
      ],
      "metadata": {
        "id": "hnAmShypVAbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def alphabetic_names(names):\n",
        "    pattern = r'[^a-zA-Z]'\n",
        "    for name in names:\n",
        "        alphaname = re.sub(pattern, \"\", name)\n",
        "        # アルファベットのみで10文字以内の名前に限定。\n",
        "        if alphaname != \"\" and len(alphaname) <= 10:\n",
        "            yield alphaname.lower()\n",
        "\n",
        "names_m = [x for x in alphabetic_names(data[\"JP\"][\"M\"])]\n",
        "names_f = [x for x in alphabetic_names(data[\"JP\"][\"F\"])]\n",
        "\n",
        "names_m"
      ],
      "metadata": {
        "id": "FkYTsaYcU2gV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ところで、両方に含まれる名前はあるでしょうか。"
      ],
      "metadata": {
        "id": "jzOCPGazW7m_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set(names_m) & set(names_f)"
      ],
      "metadata": {
        "id": "63lZkFiiW10o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "日本語は、男性名と女性名が明確に分かれていて、予測しやすいのかもしれません。\n",
        "\n",
        "これらを使い、教師データを作ります。単純に、女性なら0、男性なら1としましょう。"
      ],
      "metadata": {
        "id": "-WPoY3TGW_Oi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "gender_m = [1] * len(names_m)\n",
        "gender_f = [0] * len(names_f)"
      ],
      "metadata": {
        "id": "j8pm0MntXUPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "名前はアルファベットの列で、しかも長さが不統一です。これを、同じ長さの数値ベクトルにできれば、画像などと同じような扱いができて便利そうです。\n",
        "\n",
        "とりあえず、文字コードにおきかえ、足りない部分は0で埋めます。\n"
      ],
      "metadata": {
        "id": "TM0HQFjrXntD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(name, size=10):\n",
        "    v = [0] * (size - len(name))\n",
        "    for c in name:\n",
        "        v.append(ord(c) - 96)\n",
        "    return v\n",
        "\n",
        "encode(\"masakazu\", 10)"
      ],
      "metadata": {
        "id": "fNClHo0oYjdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors_m = [encode(name) for name in names_m]\n",
        "vectors_f = [encode(name) for name in names_f]\n",
        "\n",
        "vectors_m"
      ],
      "metadata": {
        "id": "gJxUuLFEZ65x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "男性データと女性データを統合します。"
      ],
      "metadata": {
        "id": "lv-6stcZay66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(vectors_m + vectors_f)\n",
        "Y = np.array(gender_m + gender_f)"
      ],
      "metadata": {
        "id": "X8P4_z8Za2U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "訓練用データと評価データに分けます。\n",
        "\n"
      ],
      "metadata": {
        "id": "fHUBnVAqbW43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Xtrain, Xtest, ytrain, ytest =  train_test_split(X, Y, test_size=0.2)\n",
        "ytest"
      ],
      "metadata": {
        "id": "tLVvz4FMbplj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "さあ、これで名前と性別の対応が準備できました。\n",
        "\n",
        "文字認識で使った、RandomForest分類器を使って、名前と性別の対応を学習させます。"
      ],
      "metadata": {
        "id": "qlMFim4Vadbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble        import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=1000)\n",
        "model.fit(Xtrain, ytrain)"
      ],
      "metadata": {
        "id": "e3pc7B3RactG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "これを使って、評価データを推定します。ypredは、Xtestにある名前が女性か男性かを推定した結果です。"
      ],
      "metadata": {
        "id": "_Dye4V9igRIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ypred = model.predict(Xtest)\n",
        "ypred"
      ],
      "metadata": {
        "id": "1JYieLvjgV4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "混同行列を作ります。これは、予測と正解がどれぐらい一致しているかを見るものです。"
      ],
      "metadata": {
        "id": "8cDlXg5kiJdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(ytest, ypred)\n",
        "\n",
        "cm"
      ],
      "metadata": {
        "id": "StBKkXy_gh74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "女性名320個のうち、58%の185個は正しく女性名だと判定されましたが、135個は男性名だと誤解した、という意味です。男性の名前は男性と判別しやすかったようです。\n"
      ],
      "metadata": {
        "id": "a1PTBXE2ijzz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## これは何に使える?\n",
        "\n",
        "* 定型的な作業で、訓練が必要なもの。\n",
        "* 次元が多すぎて、統計処理もままならないデータの自動ラベル付け。\n",
        "* 教師データが十分たくさんある場合。\n",
        "\n",
        "実際には、教師データを準備するのが一番大変である。機械に教えこむために必要なデータには、人間が正解を全部準備してやる必要がある。機械学習の業界では、分類器の性能を評価するための標準的な教師データがいろいろ準備されてはいるが、自分の扱いたいデータ用の教師データは自分で準備する必要がある。"
      ],
      "metadata": {
        "id": "msbx9QTfjaHj"
      }
    }
  ]
}