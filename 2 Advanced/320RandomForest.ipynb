{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "320RandomForest.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vitroid/PythonTutorials/blob/2020m0/2%20Advanced/320RandomForest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcPXmkyXy5xP",
        "colab_type": "text"
      },
      "source": [
        "# 教師あり学習の例\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbyLV3U1y5xR",
        "colab_type": "text"
      },
      "source": [
        "## 決定木による分類\n",
        "\n",
        "(Pythonデータサイエンスハンドブックp.423)\n",
        " \n",
        "次のような2次元のデータを考える。データの種類によって4つの色が割りあてられている。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMbrrI-qy5xT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "X,y = make_blobs(n_samples=300, centers=4, random_state=0, cluster_std=1.0) #散布データを生成する便利な関数\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='rainbow')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsBoDq9Oy5xb",
        "colab_type": "text"
      },
      "source": [
        "上の例では、Xに各点の座標が、yには色(0〜3)が入っている。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rERsdcIRy5xd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8e3-RZUy5xi",
        "colab_type": "text"
      },
      "source": [
        "これらの点の集合に対し、境界線を引きたい。人間にやらせれば簡単に目分量で引くだろうが、これを機械にやらせたい。\n",
        "\n",
        "最も安易な方法として、水平あるいは垂直な線で全体をおおまかに二分する。分割に際しては、色をランダムにひとつ選び、その色と、他の色の峻別が最大になるような位置で分ける。(多数決原理)\n",
        "\n",
        "(言葉で書くと簡単そうだが、自分で書くとけっこう面倒臭い。水平に境界をひくのが良いか、垂直のほうが良いか、どの色を選ぶべきかなど、うまくやらないと境界線が決まらなかったりする)\n",
        "\n",
        "指定された回数に達するか、領域に1つの色しか含まれなくなるまでこれを繰りかえす。\n",
        "\n",
        "ここでは、Scikit-learnに含まれるDecisionTreeClassifier(決定木分類器)を使うことにする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5qvPWrUy5xj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "tree = DecisionTreeClassifier().fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgwIlQWFy5xm",
        "colab_type": "text"
      },
      "source": [
        "以下の関数を使って、二分した結果を表示する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LZKVMyey5xn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_classifier(model, X, y, ax=None, cmap='rainbow'):\n",
        "    ax = ax or plt.gca()\n",
        "    # 訓練データをプロット\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=cmap, clim=(y.min(), y.max()), zorder=3)\n",
        "    ax.axis('tight')\n",
        "    ax.axis('off')\n",
        "    xlim = ax.get_xlim()\n",
        "    ylim = ax.get_ylim()\n",
        "    \n",
        "    # 推定値へのあてはめ\n",
        "    model.fit(X, y)\n",
        "    xx,yy = np.meshgrid(np.linspace(*xlim, num=200), np.linspace(*ylim, num=200))\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
        "    \n",
        "    # 色分け表示\n",
        "    n_classes = len(np.unique(y))\n",
        "    contours = ax.contourf(xx, yy, Z, alpha=0.3,\n",
        "                          levels=np.arange(n_classes+1) - 0.5,\n",
        "                          cmap=cmap, #clim=(y.min(), y.max()),\n",
        "                           zorder=1)\n",
        "    ax.set(xlim=xlim, ylim=ylim)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPIW2SQNy5xr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_classifier(DecisionTreeClassifier(max_depth=1), X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr3qB34gy5xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_classifier(DecisionTreeClassifier(max_depth=2), X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CcTrsu8y5xx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_classifier(DecisionTreeClassifier(max_depth=3), X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktlEn1hDy5xz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_classifier(DecisionTreeClassifier(max_depth=4), X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JseWnTZ-y5x2",
        "colab_type": "text"
      },
      "source": [
        "こんな風に、データをつぎつぎに二分して細分していくデータ構造をツリーと呼ぶ。(この絵では木には見えないが)\n",
        "\n",
        "これを見ると、「なんと回りくどい手順だ。もっと直観的に境界線を引けそうなのに」と思うかもしれない。しかし、上の例は2次元データだから画面上で境界が明らかに見えるが、例えばあとででてくるような64次元データになると、直感など何の役にも立たないことは容易に想像できる。機械学習の強みは、人間の直感をはるかに超えた多次元データであってもそれなりに境界を自動的に決められる点にある。\n",
        "\n",
        "上の例では、4段階まで分割を行い、それなりに良い境界線を得た。調子にのってこのまま完全に分類ができるまで細分していくとどうなるか。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy2NWsmqy5x3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_classifier(DecisionTreeClassifier(), X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X67V3Ui7y5x5",
        "colab_type": "text"
      },
      "source": [
        "境界線が不自然に複雑になってしまうのがわかると思う。これはいわゆる「過学習」である。(以前、多項式フィッティングで、不必要に複雑な曲線が得られたケースを思いだしてほしい)\n",
        "\n",
        "過学習に至ると、与えられた訓練データに対しては非常によいフィッティング性能を示すが、未知データへのあてはめで失敗する可能性が高くなる(例えば、上の図に見られる赤の小領域など)\n",
        "\n",
        "決定木分類器はこのように過学習に至りやすい。この弱点を補うために考えられたのが次のランダムフォレスト法である。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiZZxbX0y5x6",
        "colab_type": "text"
      },
      "source": [
        "### ランダムフォレスト法\n",
        "決定木分類器において、縦割りや横割りの順序、選択する色をランダムに変化させると、境界線はその都度変化する。それらを集計し、統計的に境界線を決定するのがランダムフォレスト法である。(フォレスト「森」という名前は木をたくさん生成するところから来ていると思われる)\n",
        "上のデータに対し、ランダムフォレスト法を適用すると、かなりそれらしい境界線が得られる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MAZ_ioiy5x6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble        import RandomForestClassifier\n",
        "\n",
        "visualize_classifier(RandomForestClassifier(n_estimators=100), X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgFlpkCjy5x9",
        "colab_type": "text"
      },
      "source": [
        "この結果では、一見すると決定木分類器の結果とそれほど見た目が変わらないので、ランダムフォレスト法の威力を実感できないかもしれない。そこで、もっと実用的な問題に挑戦する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE0x28nSy5x9",
        "colab_type": "text"
      },
      "source": [
        "### ランダムフォレスト法による文字分類\n",
        "\n",
        "手書き文字を学習させ、分類器を作る。\n",
        "\n",
        "手書き文字は8x8ピクセルのグレースケール画像で、それぞれの文字のデータが教師データとして与えられている。\n",
        "\n",
        "64個の数値の列から、文字を割りだすと考えると、これは64次元での分類問題と言える。\n",
        "\n",
        "学習用データを表示してみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S-SKidMy5x-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# taken from Python Data Science handbook\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()\n",
        "\n",
        "# 画像データの表示\n",
        "fig, ax = plt.subplots(8, 8, figsize=(6, 6))\n",
        "fig.subplots_adjust(left=0,right=1, bottom=0,top=1,hspace=0.05,wspace=0.05)\n",
        "for i, axi in enumerate(ax.flat):\n",
        "    axi.imshow(digits.images[i], cmap='binary')\n",
        "    axi.text(0,7,str(digits.target[i]))\n",
        "    axi.set(xticks=[], yticks=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3PCI8KXy5yC",
        "colab_type": "text"
      },
      "source": [
        "過学習かどうかを判定できるように、データを2つに分ける。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE2WtncKy5yD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 学習用データとテストデータの分割\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(digits.data, digits.target, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S53xOiSky5yF",
        "colab_type": "text"
      },
      "source": [
        "学習用データを使って、ランダムフォレスト分類器を訓練する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EX2c9yQy5yG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble        import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=1000)\n",
        "model.fit(Xtrain, ytrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJLnAo6jy5yJ",
        "colab_type": "text"
      },
      "source": [
        "それを使って、未知データの推定を行う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wISkLEssy5yJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ypred = model.predict(Xtest)\n",
        "\n",
        "# print(digits.images)\n",
        "# print(Xtest)\n",
        "# 画像データの表示\n",
        "fig, ax = plt.subplots(12, 12, figsize=(6, 6))\n",
        "fig.subplots_adjust(left=0,right=1, bottom=0,top=1,hspace=0.05,wspace=0.05)\n",
        "for i, axi in enumerate(ax.flat):\n",
        "    axi.set(xticks=[], yticks=[])\n",
        "\n",
        "    if ypred[i] != ytest[i]:\n",
        "        axi.text(0,7,str(ypred[i]), color='red')\n",
        "        axi.imshow((Xtest[i]).reshape(8,8), cmap='Reds')\n",
        "    else:\n",
        "        axi.imshow(Xtest[i].reshape(8,8), cmap='binary')\n",
        "\n",
        "\n",
        "\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(ypred, ytest))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e608JzPOy5yL",
        "colab_type": "text"
      },
      "source": [
        "144個のテストデータで4つを読み違えたので、正答率は97%である。(読み間違えた文字は人間でも分類が難しく、計算機に同情する)\n",
        "\n",
        "プログラムする人が何の工夫もすることなく、全自動でデータを学習させるだけで、これだけ分類できるのはなかなか大したものと言えるのではないだろうか。\n",
        "\n",
        "## これは何に使える?\n",
        "\n",
        "* 定型的な作業で、訓練が必要なもの。\n",
        "* 次元が多すぎて、統計処理もままならないデータの自動ラベル付け。\n",
        "* 教師データが十分たくさんある場合。\n",
        "\n",
        "実際には、教師データを準備するのが一番大変である。機械に教えこむために必要なデータには、人間が正解を全部準備してやる必要がある。機械学習の業界では、分類器の性能を評価するための標準的な教師データがいろいろ準備されてはいるが、自分の扱いたいデータ用の教師データは自分で準備する必要がある。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xXgPKI2y5yM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}