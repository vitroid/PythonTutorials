{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIxLkCvAO_QY"
   },
   "source": [
    "# ローカル環境のみ\n",
    "\n",
    "これはColabでは実行できない(カメラから画像をとりこむ)ので、File→Download→Download .ipynbから手許にコードをダウンロードして、jupyterで開いて下さい。\n",
    "\n",
    "ローカル環境は[Anaconda](https://www.anaconda.com)が快適です。\n",
    "\n",
    "Terminalから開く場合は、\n",
    "```\n",
    "jupyterlab 120opencv-Anaconda.ipynb\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FNE1ORqOUnI"
   },
   "source": [
    "# OpenCVでとにかく何か表示してみよう。\n",
    "\n",
    "> OpenCV（オープンシーヴィ、英語: Open Source Computer Vision Library）とはインテルが開発・公開したオープンソースのコンピュータビジョン向けライブラリ[1]。2009年にWillow Garage（ウィロー・ガレージ）に開発が移管された後、2015年現在はItseezがメンテナンスを行なっている[2]。なお、2016年5月26日にインテルがItseezを買収することが発表された。[Wikipedia](https://en.wikipedia.org/wiki/OpenCV)\n",
    "\n",
    "> OpenCV (Open Source Computer Vision) is a library of programming functions mainly aimed at real-time computer vision.[2] Originally developed by Intel, it was later supported by Willow Garage and is now maintained by Itseez.[1] The library is cross-platform and free for use under the open-source BSD license. [Wikipedia](https://en.wikipedia.org/wiki/OpenCV)\n",
    "\n",
    "たぶん今のPCならカメラを内蔵しているだろうから、カメラから直接とりこむのが一番てっとりばやい。\n",
    "\n",
    "Almost all note PC has a camera for Skyping.  We utilize it to capture the sample image.\n",
    "\n",
    "(Macの場合、セキュリティの確認ダイアログが表示される)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cW5PvN6LOUnJ"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NRhvrprjOUnL"
   },
   "outputs": [],
   "source": [
    "# OpenCVライブラリを読みこむ。\n",
    "import cv2\n",
    "# 画像操作ライブラリ\n",
    "from PIL import Image \n",
    "\n",
    "# Device ID of the camera would be 0\n",
    "# カメラのデバイス番号は0番になっていることが多い。\n",
    "# デバイス番号の代わりに動画ファイルを指定することもできる。\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "# Capture a frame from the camera.\n",
    "# カメラから1フレーム読みこむ。retがFalseになったら読み損ねている。\n",
    "ret, image = camera.read()\n",
    "\n",
    "# 画像の大きさを640x360に縮小。(カメラによっては(640,480)の場合も)\n",
    "image = cv2.resize(image, (640,360))\n",
    "\n",
    "# 絵が暗い場合は次の行を追加\n",
    "image *= 4\n",
    "\n",
    "# Jupyterの中で表示\n",
    "# 画像はnumpy arrayの形になっていて、image[行, 列, 色]\n",
    "# OpenCVの色はBGR順だが通常はRGB順なので、displayする時に順番を入れかえる。\n",
    "display(Image.fromarray(image[:,:,::-1]))\n",
    "# 以下の例ではdisplayは使わないので気にしなくていい\n",
    "\n",
    "# 画像のサイズを見る。\n",
    "print(image.shape)\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3tCQnjBOUnM"
   },
   "source": [
    "imageの中身に注目して下さい。整数値の三つ組がたくさんはいった,3次元のnumpy arrayになっています。\n",
    "3つ組の数字はRGB(三原色)を表現していて、写真の画素一つ一つの色がすべて含まれています。\n",
    "それが行ごとにまとめられ、すべての行をまとめたものが1枚の写真になります。\n",
    "つまり、numpyのarrayの操作さえ知っていれば、写真を自由に操作できる、ということになります。\n",
    "\n",
    "See the content of the `image` variable. It is a three-dimensional numpy array of integers.\n",
    "The innermost triplets express the intensities of the three primitive colors, blue, green, and red, at a single pixel.\n",
    "Pixels are bundled to make a row, and the rows are budled to make the whole image.\n",
    "That is, if you know how to access and modify the numpy array, you can also process the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qodT65cYOUnM"
   },
   "source": [
    "`row`行目のピクセルの色は、`image[row]`あるいは`image[row,:,:]`で参照できます。\n",
    "\n",
    "Colors of the pixels at the `row` are referred to as `image[row]` or `image[row,:,:]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C56zj-iZOUnM"
   },
   "outputs": [],
   "source": [
    "image[100,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZtKQMMnOUnN"
   },
   "source": [
    "`row`行目、`col`列目のピクセルの色は、`image[row,col]`あるいは`image[row,col,:]`で参照できます。\n",
    "\n",
    "Color of the pixel at (`row`, `col`) is referred to as `image[row,col]` or `image[row,col,:]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "642qRBMOOUnN"
   },
   "outputs": [],
   "source": [
    "image[100,200,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1rwsYEcOUnN"
   },
   "source": [
    "`row`行目、`col`列目のピクセルの赤色の強度は、`image[row,col,2]`で参照できます。色の順番はRGBではなくBGR(0=Blue, 1=Green, 2=Red)です。\n",
    "\n",
    "The red strength of the pixel at (`row`, `col`) is referred to as `image[row,col,2]`. Note that color order is not RGB but BGR (blue is 0, green is 1, red is 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LB6CDVCVOUnO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image[100,200,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_Q80nY6OUnO"
   },
   "source": [
    "画像は`imwrite()`関数を使って保存できます。\n",
    "\n",
    "The obtained image can be saved with `imwrite()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xjPlQTW3OUnO"
   },
   "outputs": [],
   "source": [
    "cv2.imwrite(\"test.jpg\", image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9AtZmzDQOUnP"
   },
   "source": [
    "上の例では1枚の写真が得られるだけですが、これをくりかえせば、ムービーになります。\n",
    "動画のウィンドウ上で何かキーを押せばプログラムが終わるようになっています。\n",
    "画像解像度が高すぎる場合は、resize関数で小さくして下さい。\n",
    "\n",
    "In the example above, only one image is obtained. If you repeat the process with a loop, you get a movie.\n",
    "If the picture size is too large to be displayed, use `resize()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tdbCaQKjOUnP"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "camera = cv2.VideoCapture(0)  #Device ID of the camera would be 0\n",
    "\n",
    "while cv2.waitKey(1) < 0:\n",
    "    ret, image = camera.read()\n",
    "    image = cv2.resize(image, (640,360))\n",
    "    cv2.imshow(\"Hello!\", image)\n",
    "\n",
    "#Close all the windows.  \n",
    "cv2.destroyAllWindows()\n",
    "# cv2.waitKey(1)\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IE2WtW1LOUnQ"
   },
   "source": [
    "## 簡単な画像処理\n",
    "色の明るさは0〜255の整数で表現されていますから、色調を完全に反転させるには、255から引きます。\n",
    "\n",
    "カメラからとりこんだ画像を、ウィンドウに表示する前に、処理をすれば、処理後の画像を見ることができます。\n",
    "もちろん、2つウィンドウをひらいて、両方見比べることも簡単です。\n",
    "\n",
    "Color intensities are expressed by the integer number between 0 (dark) and 255 (bright). Therefore, if you want to invert the colors, subtract them from 255.\n",
    "\n",
    "In the following sample, the original and inverted images are shown in a different window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XwO_6N2JOUnR"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "camera = cv2.VideoCapture(0)  #Device ID of the camera would be 0\n",
    "\n",
    "while cv2.waitKey(1) < 0:\n",
    "    ret, image = camera.read()\n",
    "    image = cv2.resize(image, (640,360))\n",
    "    reversed_image = 255 - image #reverse the colors (numpy operation)\n",
    "\n",
    "    cv2.imshow(\"Hello!\", image)\n",
    "    cv2.imshow(\"!olleH\", reversed_image)  #Show the reversed image\n",
    "\n",
    "#Close all the windows.  \n",
    "cv2.destroyAllWindows()\n",
    "camera.release()\n",
    "cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2G1m50TOUnR"
   },
   "source": [
    "赤だけを反転するには? ここでもnumpyのarray操作が使えます。\n",
    "\n",
    "Can we then invert the red component only?  Numpy is useful for such an operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9YZvwGDZOUnS"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "camera = cv2.VideoCapture(0)  #Device ID of the camera would be 0\n",
    "\n",
    "while cv2.waitKey(1) < 0:\n",
    "    ret, image = camera.read()\n",
    "    image = cv2.resize(image, (640,360))\n",
    "    image2 = image.copy() #firstly make the copy of the image\n",
    "    image2[:,:,2] = 255 - image2[:,:,2]  #Color order in OpenCV is not RGB but BGR.\n",
    "\n",
    "    cv2.imshow(\"Hello!\", image)\n",
    "    cv2.imshow(\"!olleH\", image2)  #Show the reversed image\n",
    "\n",
    "#Close all the windows.  \n",
    "cv2.destroyAllWindows()\n",
    "camera.release()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x40H4k0sOUnS"
   },
   "source": [
    "上下を入れかえたいなら、行を反転すればいいのです。\n",
    "\n",
    "If you want to make the image upside-down, just invert the order of image rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jopW_9sOUnT"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "camera = cv2.VideoCapture(0)  #Device ID of the camera would be 0\n",
    "\n",
    "while cv2.waitKey(1) < 0:\n",
    "    ret, image = camera.read()\n",
    "    image = cv2.resize(image, (640,360))\n",
    "    upsidedown = image[::-1,:,:] \n",
    "\n",
    "    cv2.imshow(\"Hello!\", image)\n",
    "    cv2.imshow(\"!olleH\", upsidedown)  #Show the reversed image\n",
    "\n",
    "#Close all the windows.  \n",
    "cv2.destroyAllWindows()\n",
    "camera.release()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dr5AK06NOUnT"
   },
   "source": [
    "下半分を反転して上半分にもっていくと、かっこいいビデオエフェクトになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2qyzrLxZOUnU"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "camera = cv2.VideoCapture(0)  #Device ID of the camera would be 0\n",
    "\n",
    "while cv2.waitKey(1) < 0:\n",
    "    ret, image = camera.read()\n",
    "    image = cv2.resize(image, (640,360))\n",
    "    image[0:180] = image[:179:-1]\n",
    "    cv2.imshow(\"Hello!\", image)\n",
    "\n",
    "#Close all the windows.  \n",
    "cv2.destroyAllWindows()\n",
    "camera.release()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mj-ur-9QOUnU"
   },
   "source": [
    "## 宿題1\n",
    "右半分を反転して左半分に表示するようにしてみましょう。\n",
    "\n",
    "Fold the right half onto the left half of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nbn2N8wOUnU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wTzyO-0OUnV"
   },
   "source": [
    "## 録画\n",
    "ちなみに、録画はこんな風に書きます。(動かない可能性が高いですが)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pu3FJ4EQOUnV"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "camera = cv2.VideoCapture(0)  #Device ID of the camera would be 0\n",
    "\n",
    "# 出力先を指定\n",
    "out = cv2.VideoWriter(\"test.avi\", # file name\n",
    "                      cv2.VideoWriter_fourcc(*'XVID'), # おまじない\n",
    "                      10,         # frame rate\n",
    "                      (640,360))  # size\n",
    "\n",
    "while cv2.waitKey(1) < 0:\n",
    "    ret, image = camera.read()\n",
    "    image = cv2.resize(image, (640,360))\n",
    "    image[0:180] = image[:179:-1]\n",
    "    cv2.imshow(\"Hello!\", image)\n",
    "    # Write a frame to the video file.\n",
    "    out.write(image)\n",
    "\n",
    "#Close all the windows.\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "#Close video file\n",
    "out.release()\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixRgl_31OUnW"
   },
   "source": [
    "カメラを何台も連結し、その画像を全部とりこんで、防犯カメラとして使うのも、ここまでの知識でできそうですね。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ubb8lkp2OUnW"
   },
   "source": [
    "## 少し高度な画像処理 More tricks\n",
    "瞬間瞬間の画像を加工するのではなく、時間変化をとらえてみましょう。以下の例では、直前の画像をlastimage変数に保存しておき、absdiff関数で画像の差分を作ります。\n",
    "\n",
    "Instead of processing an instantaneous image, let us process the difference.  In the following example, the captured image is stored in `lastimage` and compare it with the new capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "pNBxx6i7OUnW",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "camera = cv2.VideoCapture(0)  #Device ID of the camera would be 0\n",
    "\n",
    "ret, image = camera.read()   #Obtain the first image\n",
    "lastimage = cv2.resize(image, (640,360))  #and resize it.\n",
    "while cv2.waitKey(1) < 0:\n",
    "    ret, image = camera.read()\n",
    "    image = cv2.resize(image, (640,360))\n",
    "    diff = cv2.absdiff(image, lastimage)\n",
    "    # 明暗を反転して表示\n",
    "    # Show inverted image\n",
    "    cv2.imshow(\"Hello!\", 255 - diff)\n",
    "    lastimage = image\n",
    "\n",
    "#Close all the windows.  \n",
    "cv2.destroyAllWindows()\n",
    "camera.release()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_pwKKAWOUnW"
   },
   "source": [
    "爬虫類や両生類は、動いているものしか見えないと言います。たぶん彼らの見ている世界はこんな感じなのでしょう。\n",
    "\n",
    "It is said that reptiles and amphibians only see the moving things. Perhaps they are looking the world like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtW1Vz_rOUnX"
   },
   "source": [
    "OpenCVの関数で、輪郭抽出するCannyを使ってみましょう。これは動きを検出するわけではなく、静止画1枚から輪郭を見つけます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DaK_WZTKOUnX"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "camera = cv2.VideoCapture(0)  #Device ID of the camera would be 0\n",
    "\n",
    "ret, image = camera.read()   #Obtain the first image\n",
    "while cv2.waitKey(1) < 0:\n",
    "    ret, image = camera.read()\n",
    "    image = cv2.resize(image, (640,360))\n",
    "    diff = cv2.Canny(image, 100, 200) #min and max\n",
    "    cv2.imshow(\"Hello!\", diff)\n",
    "\n",
    "#Close all the windows.  \n",
    "cv2.destroyAllWindows()\n",
    "camera.release()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WH6zo0eZOUnX"
   },
   "source": [
    "面白いのでもっと遊んでみます。輪郭線をもとの画像に重ねてみます。世界がアニメ風になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wp9C1DvUOUnX"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "camera = cv2.VideoCapture(0)  #Device ID of the camera would be 0\n",
    "\n",
    "ret, image = camera.read()   #Obtain the first image\n",
    "while cv2.waitKey(1) < 0:\n",
    "    ret, image = camera.read()\n",
    "    image = cv2.resize(image, (640,360))\n",
    "    diff = cv2.Canny(image, 10, 200) #min and max\n",
    "\n",
    "    # diffの値が0でない(=白)の部分だけ、imageを0にする。\n",
    "    image[diff>0] = 0  \n",
    "\n",
    "    cv2.imshow(\"Hello!\", image)\n",
    "\n",
    "#Close all the windows.  \n",
    "cv2.destroyAllWindows()\n",
    "camera.release()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zzojf750OUnX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnvgfr9HOUnX"
   },
   "source": [
    "## 高度な画像処理 Advanced image processing\n",
    "OpenCVは最先端の画像処理ライブラリなので、単なる画像の編集以上のことができます。私たちは画像処理の専門家ではないので、技術的な内容まではよくわかりませんが、とにかく利用することならできます。\n",
    "\n",
    "次の例では、Background Subtractionという技術を使い、背景と動いている物体を区別して、動きがあった部分だけを切り抜きます。\n",
    "\n",
    "https://docs.opencv.org/3.4/db/d5c/tutorial_py_bg_subtraction.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_d3QcHhgOUnY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "camera = cv2.VideoCapture(0)\n",
    "# BackgroundSubtractorを作成。いつものように中身はブラックボックス\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while cv2.waitKey(1) < 0:\n",
    "    ret, image = camera.read()\n",
    "    image = cv2.resize(image, (640,360))\n",
    "    # BackgroundSubtractorに画像を渡すと、マスクを生成する。\n",
    "    fgmask = fgbg.apply(image)\n",
    "    cv2.imshow(\"Image\", image)\n",
    "    cv2.imshow(\"Mask\", fgmask)\n",
    "\n",
    "#Close all the windows.  \n",
    "cv2.destroyAllWindows()\n",
    "camera.release()\n",
    "cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmk6I9B3OUnY"
   },
   "source": [
    "マスクというのは、画像のなかで注目する部分だけを白にした、白黒画像のことです。マスクを使うと、画像を切り抜けます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qTs6-7HOOUnY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from time import sleep\n",
    "\n",
    "camera = cv2.VideoCapture(0)\n",
    "# BackgroundSubtractorを作成。いつものように中身はブラックボックス\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "\n",
    "while cv2.waitKey(1) < 0:\n",
    "    ret, image = camera.read()\n",
    "    image = cv2.resize(image, (640,360))\n",
    "    # BackgroundSubtractorに画像を渡すと、マスクを生成する。\n",
    "    fgmask = fgbg.apply(image)\n",
    "    \n",
    "    # fgmaskの値が0の部分だけ、画像も0にする\n",
    "    image[fgmask==0] = 0\n",
    "    cv2.imshow(\"Masked Image\", image)\n",
    "    # 0.1秒待たせ、わざとコマ送りにします。\n",
    "    sleep(0.1)\n",
    "\n",
    "#Close all the windows.  \n",
    "cv2.destroyAllWindows()\n",
    "camera.release()\n",
    "cv2.waitKey(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KaWCTYxNOUnY"
   },
   "source": [
    "動いた部分だけを上書きしていくと?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Iv4iwbCOUnY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from time import sleep\n",
    "\n",
    "camera = cv2.VideoCapture(0)\n",
    "# BackgroundSubtractorを作成。いつものように中身はブラックボックス\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# 最初のコマをfirstに入れておきます。\n",
    "ret, first = camera.read()\n",
    "first = cv2.resize(first, (640,360))\n",
    "\n",
    "while cv2.waitKey(1) < 0:\n",
    "    ret, image = camera.read()\n",
    "    image = cv2.resize(image, (640,360))\n",
    "    # BackgroundSubtractorに画像を渡すと、マスクを生成する。\n",
    "    fgmask = fgbg.apply(image)\n",
    "    \n",
    "    # fgmaskの値が0でない部分だけ、imageの内容をfirstに上書きする\n",
    "    first[fgmask>0] = image[fgmask>0]\n",
    "    # 動いた部分だけが書き加えられます。\n",
    "    # 左右は反転したほうがわかりやすい。\n",
    "    cv2.imshow(\"Canvas\", first[:, ::-1, :])\n",
    "    # 0.1秒待たせ、わざとコマ送りにします。\n",
    "    sleep(0.1)\n",
    "\n",
    "#Close all the windows.  \n",
    "cv2.destroyAllWindows()\n",
    "camera.release()\n",
    "cv2.waitKey(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSx8DlIKOUnZ"
   },
   "source": [
    "最近のカメラのように、映像の中に顔を見付けだす実験をやってみます。といっても、自分ではその方法が見当もつかないので、Googleに頼ります。\n",
    "\n",
    "Googleで\"OpenCV python face detection\" \"OpenCV python 顔認識\" などのキーワードで検索すると、10行程度のコードを書くだけで顔認識してくれることがわかります。今回は、[http://qiita.com/wwacky/items/98d8be2844fa1b778323](http://qiita.com/wwacky/items/98d8be2844fa1b778323) のコードを読み、上で書いたプログラムに組み込んで、動画からリアルタイムで顔を認識するようにしてみましょう。\n",
    "\n",
    "Since OpenCV is a state-of-the-art image processing library, it can do more than just editing images. We are not experts in image processing, so we do not know the technical content well, but we can do it anyway.\n",
    "\n",
    "Let us try to detect the faces in the captured image like a recent digital cameras and smart phones.\n",
    "\n",
    "Giving the keywords such as \"OpenCV python face recognition\" on Google, you can get the codes for face recognition.  They are only 10 lines of Python.  For this time, I read the code of [http://qiita.com/wwacky/items/98d8be2844fa1b778323] (http://qiita.com/wwacky/items/98d8be2844fa1b778323) and incorporate it into the program written above.\n",
    "\n",
    "コードをそのままコピーするのははばかられるので、要点だけ書くと、\n",
    "\n",
    "Essential parts of the code are following.\n",
    "\n",
    "```\n",
    "    #HAAR分類器の顔検出用の特徴量。顔らしさの指標。これはOpenCVのサンプルコードに付属しているものをそのまま利用。\n",
    "    #Feature collection of the faces for HAAR classifier. It is contained in the sample code for OpenCV.\n",
    "    cascade_path = \"haarcascade_frontalface_alt.xml\"\n",
    "\n",
    "    #グレースケール変換。モノクロ画像で認識するらしい。\n",
    "    #この部分はOpenCV3で書き方が変わったらしい。\n",
    "    #It converts a color image into a gray image.\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #カスケード分類器の特徴量を取得する。ループの外で一回だけ実行するだけでよさそう。\n",
    "    #Initializer for the feature detector.  Must be executed only once (outside the loop)\n",
    "    cascade = cv2.CascadeClassifier(cascade_path)\n",
    "\n",
    "    #物体認識（顔認識）の実行。facerectには、顔を含む領域の長方形(複数)が入る。\n",
    "    #Feature detection. It returns the list of rectangles in which faces are detected.\n",
    "    facerect = cascade.detectMultiScale(image_gray, scaleFactor=1.1, minNeighbors=1, minSize=(1, 1))\n",
    "\n",
    "    #imageに長方形を描きこむ関数。\n",
    "    #It draws a rectangle on the given image.\n",
    "    cv2.rectangle(image, tuple(rect[0:2]),tuple(rect[0:2]+rect[2:4]), color, thickness=2)\n",
    "```\n",
    "\n",
    "これらを、上のコードに埋めこみます。\n",
    "\n",
    "Let us embed them in our program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特徴量ファイルの入手。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/mitre/biqt-face/master/config/haarcascades/haarcascade_frontalface_alt2.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0yqfHy_mOUnZ"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "camera = cv2.VideoCapture(0)  #Device ID of the camera would be 0\n",
    "\n",
    "#HAAR分類器の顔検出用の特徴量。顔らしさの指標。これはOpenCVのサンプルコードに付属しているものをそのまま利用。\n",
    "cascade_path = \"haarcascade_frontalface_alt2.xml\"\n",
    "#カスケード分類器の特徴量を取得する。ループの外で一回だけ実行するだけでよさそう。\n",
    "cascade = cv2.CascadeClassifier(cascade_path)\n",
    "\n",
    "while cv2.waitKey(1) < 0:\n",
    "    ret, image = camera.read()\n",
    "    image = cv2.resize(image, (640,360))\n",
    "    #グレースケール変換。モノクロ画像で認識するらしい。\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    #物体認識（顔認識）の実行。facerectには、顔を含む領域の長方形(複数)が入る。\n",
    "    facerect = cascade.detectMultiScale(image_gray, scaleFactor=1.3, minNeighbors=2)\n",
    "\n",
    "    for (x,y,w,h) in facerect:\n",
    "        #imageに長方形を描きこむ関数。\n",
    "        cv2.rectangle(image, (x,y), (x+w,y+h), (0,255,0), thickness=2)\n",
    "\n",
    "    cv2.imshow(\"Hello!\", image)\n",
    "\n",
    "#Close all the windows.  \n",
    "cv2.destroyAllWindows()\n",
    "camera.release()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHmPv38kOUnZ"
   },
   "source": [
    "顔だけ重ね描きしてみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pOR3YpTLOUnZ"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "camera = cv2.VideoCapture(0)  #Device ID of the camera would be 0\n",
    "\n",
    "#HAAR分類器の顔検出用の特徴量。顔らしさの指標。これはOpenCVのサンプルコードに付属しているものをそのまま利用。\n",
    "cascade_path = \"haarcascade_frontalface_alt2.xml\"\n",
    "#カスケード分類器の特徴量を取得する。ループの外で一回だけ実行するだけでよさそう。\n",
    "cascade = cv2.CascadeClassifier(cascade_path)\n",
    "\n",
    "#最初の1枚。これに上書きしていく。\n",
    "ret, canvas = camera.read()\n",
    "canvas = cv2.resize(canvas, (640,360))\n",
    "\n",
    "while cv2.waitKey(1) < 0:\n",
    "    ret, image = camera.read()\n",
    "    image = cv2.resize(image, (640,360))\n",
    "    #グレースケール変換。モノクロ画像で認識するらしい。\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    #物体認識（顔認識）の実行。facerectには、顔を含む領域の長方形(複数)が入る。\n",
    "    facerect = cascade.detectMultiScale(image_gray, scaleFactor=1.3, minNeighbors=2)\n",
    "\n",
    "    for (x,y,w,h) in facerect:\n",
    "        #canvasに顔の部分だけを描きこむ.\n",
    "        canvas[y:y+h, x:x+w] = image[y:y+h, x:x+w]\n",
    "    cv2.imshow(\"Hello!\", canvas)\n",
    "\n",
    "#Close all the windows.  \n",
    "cv2.destroyAllWindows()\n",
    "camera.release()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LX8b0gUqOUna"
   },
   "source": [
    "顔をモザイクにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trtLv1tUOUna"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "camera = cv2.VideoCapture(0)  #Device ID of the camera would be 0\n",
    "\n",
    "#HAAR分類器の顔検出用の特徴量。顔らしさの指標。これはOpenCVのサンプルコードに付属しているものをそのまま利用。\n",
    "cascade_path = \"haarcascade_frontalface_alt2.xml\"\n",
    "#カスケード分類器の特徴量を取得する。ループの外で一回だけ実行するだけでよさそう。\n",
    "cascade = cv2.CascadeClassifier(cascade_path)\n",
    "\n",
    "while cv2.waitKey(1) < 0:\n",
    "    ret, image = camera.read()\n",
    "    image = cv2.resize(image, (640,360))\n",
    "    #グレースケール変換。モノクロ画像で認識するらしい。\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    #物体認識（顔認識）の実行。facerectには、顔を含む領域の長方形(複数)が入る。\n",
    "    facerect = cascade.detectMultiScale(image_gray, scaleFactor=1.3, minNeighbors=2)\n",
    "\n",
    "    for (x,y,w,h) in facerect:\n",
    "        # 四角の中だけ切りだす。\n",
    "        square = image[y:y+h,x:x+w]\n",
    "        # 6x6 pixelに縮小する。\n",
    "        small = cv2.resize(square, (6,6))\n",
    "        # もとの大きさに拡大する。\n",
    "        reduced = cv2.resize(small, (w,h), interpolation=cv2.INTER_NEAREST)\n",
    "        # imageに戻す。\n",
    "        image[y:y+h,x:x+w] = reduced\n",
    "\n",
    "    cv2.imshow(\"Hello!\", image)\n",
    "\n",
    "#Close all the windows.  \n",
    "cv2.destroyAllWindows()\n",
    "camera.release()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGmeH5g-OUna"
   },
   "source": [
    "あるいは、顔だけを常に画面一杯に表示させることもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iOF43dVNOUna"
   },
   "outputs": [],
   "source": [
    "def maxcontrast(img):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/39308030/how-do-i-increase-the-contrast-of-an-image-in-python-opencv\n",
    "    \"\"\"\n",
    "    #-----Converting image to LAB Color model----------------------------------- \n",
    "    lab= cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    #-----Splitting the LAB image to different channels-------------------------\n",
    "    l, a, b = cv2.split(lab)\n",
    "\n",
    "    #-----Applying CLAHE to L-channel-------------------------------------------\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l)\n",
    "\n",
    "    #-----Merge the CLAHE enhanced L-channel with the a and b channel-----------\n",
    "    limg = cv2.merge((cl,a,b))\n",
    "    cv2.imshow('limg', limg)\n",
    "\n",
    "    #-----Converting image from LAB Color model to RGB model--------------------\n",
    "    final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zPwGhI1WOUna"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "camera = cv2.VideoCapture(0)  #Device ID of the camera would be 0\n",
    "\n",
    "#HAAR分類器の顔検出用の特徴量。顔らしさの指標。これはOpenCVのサンプルコードに付属しているものをそのまま利用。\n",
    "cascade_path = \"haarcascade_frontalface_alt2.xml\"\n",
    "#カスケード分類器の特徴量を取得する。ループの外で一回だけ実行するだけでよさそう。\n",
    "cascade = cv2.CascadeClassifier(cascade_path)\n",
    "\n",
    "while cv2.waitKey(1) < 0:\n",
    "    ret, image = camera.read()\n",
    "    image = cv2.resize(image, (640,360))\n",
    "    #グレースケール変換。モノクロ画像で認識するらしい。\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    #物体認識（顔認識）の実行。facerectには、顔を含む領域の長方形(複数)が入る。\n",
    "    facerect = cascade.detectMultiScale(image_gray, scaleFactor=1.3, minNeighbors=2)\n",
    "\n",
    "    for (x,y,w,h) in facerect:\n",
    "        # 四角の中だけ切りだす。\n",
    "        square = image[y:y+h,x+w-1:x-1:-1]\n",
    "        #diff = cv2.Canny(square, 100, 200) #min and max\n",
    "        # diffの値が0でない(=白)の部分だけ、imageを0にする。\n",
    "        #square[diff>0] = 0  \n",
    "\n",
    "        # 16x16 pixelに縮小する。\n",
    "        small = cv2.resize(square, (16,16))\n",
    "        # 500x500に拡大する。\n",
    "        reduced = cv2.resize(small, (200,200), interpolation=cv2.INTER_NEAREST)\n",
    "        cv2.imshow(\"Hello!\", reduced)\n",
    "        break\n",
    "\n",
    "#Close all the windows.  \n",
    "cv2.destroyAllWindows()\n",
    "camera.release()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMhhse09OUna"
   },
   "source": [
    "こういうプログラムは何に使えるの? 何でしょうね。例えば、\n",
    "\n",
    "* 顔認識は、顕微鏡写真から、細胞の核の個数を数えたりできるでしょう。その場合、特徴量ファイルを細胞核用に準備する必要はあります。\n",
    "* 動きの検出は、遅い反応や、まれにしかおこらない現象を監視するのに使えます。もちろん、防犯カメラにも。\n",
    "\n",
    "OpenCVのすべての機能はとても紹介しきれませんが、画像処理を専門としている研究者たちが、OpenCVを使って新しい画像処理方法を見付けたり、逆に新しいアルゴリズムをOpenCVに追加したりしています。OpenCVを使えれば、それらの最新の技術を自分の研究にとりこんでいけるのです。\n",
    "\n",
    "\n",
    "How can we use them for our research?\n",
    "\n",
    "* Face recognition can count the number of cell nuclei from the photomicrograph. In that case, you need to prepare the feature file for the cell nucleus.\n",
    "* Motion detection can be used to monitor slow reactions or rare phenomena. Of course, also for security cameras.\n",
    "\n",
    "Researchers who specialize in image processing use OpenCV to find a new image processing method and add new algorithms to OpenCV. With OpenCV, you can incorporate those latest technologies into your own research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpDLC23WOUnb"
   },
   "source": [
    "## 間にあわなかった物ども\n",
    "\n",
    "[OpenCVの機能リスト](https://docs.opencv.org/3.0-beta/modules/refman.html)を見ると、ほかにも面白そうな機能がたくさんありますね。まだまだ修行が必要です。\n",
    "\n",
    "* ビデオスタビライザー\n",
    "* 超解像\n",
    "* QRコードの認識\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_ST1Fq_OUnb"
   },
   "source": [
    "## 宿題2\n",
    "\n",
    "PythonでOpenCVを使った作例をネットで検索して、Jupyter上で動くことを確認して下さい。\n",
    "\n",
    "今回はコピペでも構いませんが、可能ならアレンジを加えて下さい。いずれの場合も出典を示して下さい。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKLLBwa8OUnb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "slzUTm8lOUnb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "120opencv-Anaconda.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
